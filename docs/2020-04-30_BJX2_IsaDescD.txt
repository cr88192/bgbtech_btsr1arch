== Instructions Organized by Name with Descriptions ==

Register Aliases:
* DLR will be an alias for R0.
* DHR will be an alias for R1.
* SP will be an alias for R15.


Notation:
* 0..9, A..F: Literal Hexadecimal Values
* e: The 'E' bits 'QNMI'
** Q will give an operation size or type.
** N will give Bit 4 of the N field (usually Rn).
** M will give Bit 4 of the M field (usually Rm).
** I will give Bit 4 of the O field (usually Ro).
*** Alternately may serve as the MSB for an immediate.
*** If no Ro or Imm, serves a role similar to Q.
* f: -
* g: E bits (3R), but Q=0, thus 0nmi
* G: E bits (3R), but Q=1, thus 1nmi
* h: E bits (I,R), but Q=0, thus 0nii or 0iin
* H: E bits (I,R), but Q=1, thus 1nii or 1iin
** Two of the register fields will be interpreted as an immediate.
* i: Immediate (Signed)
* j: Immediate (Unsigned)
* m: Source Register
* n: Destination Register
* o: Index or Secondary Register
* p: E bits (2R), but Q=0, I=0, thus 0nm0
* P: E bits (2R), but Q=1, I=0, thus 1nm0
* q: E bits (2R), but Q=0, I=1, thus 0nm1
* Q: E bits (2R), but Q=1, I=1, thus 1nm1

Single register forms in 30zz..37zz will be mirrored in 38zz..3Fzz, but will encode on R16..R31 rather than R0..R15.

The instructions in the F0zz..F3zz range will repeat in F4zz..F7zz (Parallel), E0zz..E3zz (Execute if True), and E4zz..E7zz (Execute if False) ranges.

The instructions in the F8zz/F9zz range will repeat in FCzz/FDzz (Parallel), E8zz/E9zz (Execute if True), and ECzz/EDzz (Execute if False) ranges.


The 7wnm_ZeoZ range will repeat the F0nm_ZeoZ range, just with the register fields extended to 6 bits, and the high bit of W will encode the WEX flag.

The 9wnm_Zeii range will repeat the F2nm_Zeii and F1nm_Zeii and ranges, with 6 bit register IDs, just with Wi working as a range selector.

The FEii_iiii-Fzzz_zzzz space will extend the immediate field by 24 bits for encodings which have an immediate. 'FE' or 'FE-FE' may be used as a shorthand for encodings which have one or two jumbo prefixes.

The FFw0_0pii-Fzzz_zzzz space (W0) will repeat the entire 32-bit encoding space, just with registers expanded to 6 bits, and any immediate fields extended by 8 bits (MBZ for instructions which do not have an immediate field).

Given the same base instructions apply to every sub-range, typically only those in the base ranges will be listed, except when the sub-range instruction differs from the base-range instruction.



Immediates may have a suffix to indicate how the value is extended:
* u: Value is extended with zeroes.
* n: Value is extended with ones.
* s: Value is sign extended.


=== ADC ===

* 12nm       ADC		Rm, Rn
* F0nm_1g29  ADC		Rm, Rn

Add with Carry, Rn=Rn+Rm+SR.T, with SR.T being updated to reflect the carry-out bit.

WEX: ADC will only update SR.T in Lane 1. If an ADC is in another lane, the state of SR.T will be undefined following the operation.


=== ADD ===

* 10nm       ADD		Rm, Rn
* 58nm       ADD		Rm, DLR, Rn			//Rn=Rm+DLR
* Cnii       ADD		Imm8s, Rn
* F0nm_1go0  ADD		Rm, Ro, Rn			//Rn=Rm+Ro
* F0nm_1e09  ADD		Rm, Rn				//Rn=Rn+Rm
* F2nm_0gjj  ADD		Rm, Imm9u, Rn		//
* F2nm_1gjj  ADD		Rm, Imm9n, Rn		//
* F84n_iiii  ADD		Imm16s, Rn
* F85n_iiii  ADD		Imm16s, Rk

* FE-FE F84n_iiii  ADD	Imm64, Rn		//R0 ..R15
* FE-FE F85n_iiii  ADD	Imm64, Rk		//R16..R31
* FE-FE F86n_iiii  ADD	Imm64, Rk		//R32..R47
* FE-FE F87n_iiii  ADD	Imm64, Rk		//R48..R63

Add the source and destination values and store the result in the destination register.


=== ADDx.L ===

* F0nm_5goC  ADDS.L	Rm, Ro, Rn
* F0nm_5GoC  ADDU.L	Rm, Ro, Rn
* F2gj_3gjj  ADDS.L	Rm, Imm9u, Rn
* F2nm_3Gjj  ADDU.L	Rm, Imm9u, Rn
* F2nm_4gjj  ADDS.L	Rm, Imm9n, Rn
* F2nm_4Gjj  ADDU.L	Rm, Imm9n, Rn

Add the source and destination values and store the result in the destination register.

This form sign or zero extends the 32-bit result to 64 bits.


=== AND ===

* 15nm       AND		Rm, Rn
* 5Anm       AND		Rm, DLR, Rn
* F0nm_1go5  AND		Rm, Ro, Rn
* F0nm_1e59  AND		Rm, Rn
* F2nm_5gjj  AND		Rm, Imm9u, Rn

Perform a bitwise AND of the source and destination values and store the result in the destination register.


=== BCDADC / BCDSBB (BCD) ===

* F0nm_1g88 BCDADC	Rm, Rn
* F0nm_1g98 BCDSBB	Rm, Rn

Perform addition or subtraction of Packed BCD numbers.

The SR.T flag is used as a Carry or Borrow flag, and is updated based the result of the leftmost digit.

For this instruction, the 64-bit register is interpreted as a 16-digit BCD number, with each 4 bits corresponding to a decimal digit (0..9). When performing an addition, if the result of adding a pair of digits (plus the carry) is larger than 9, then 6 will be added in this location (so A maps to 0, B to 1, ...), and a carry will be propagated to the next digit.

The SBB case will be similar to ADC, but will perform a 9s complement remapping (0123456789 -> 9876543210) on Rm and will invert the value of SR.T.


These instructions may be daisy-chained to support larger numbers.

This instruction is only allowed in Lane 1.


=== BF / JF ===

* 23dd       BF		(PC, disp8s)
* 31n3       BF		(PC, Rn)
* F013_3en0  BF		(PC, Rn)			//Fix32
* F0dd_Fddd  BF		(PC, disp20s)		//Branch False, +/- 1MB

* 32n3       JF		Rn
* F023_3en0  JF		Rn					//Fix32

* FFw0_0ddd_F0dd_Fddd  BF	(PC, Disp33s)

Branch if False (SR.T is 0).
The target address is computed and PC is updated to the new address if the condition is met.

This instruction is only allowed in Lane 1.


=== BRA / JMP ===

* 20dd       BRA		(PC, disp8s)
* 31n0       BRA		(PC, Rn)
* F010_3en0  BRA		(PC, Rn)			//Fix32
* F0dd_Cddd  BRA		(PC, disp20s)		//Fix32

* 32n0       JMP		Rn
* F020_3en0  JMP		Rn					//Fix32

* FEjj_jjjj_F202_C4jj /	BRA		(PC, disp33s)
* FFw0_0ddd_F0dd_Cddd	BRA		(PC, Disp33s)
* FFjj_jjjj_FAjj_jjjj	JMP		Abs48		//Abs48 Branch

Branch to Address.
For BRA, the target address is computed and PC is updated to the new address.

For JMP, this performs an absolute jump to the address given.

As a special case, if JMP is used with DHR, the high order bits of DHR will be interpreted as if this were an RTS instruction (copying these bits into the SR user flags). Otherwise, the contents of the SR user flags will be unmodified.

This instruction is only allowed in Lane 1.


=== BREAK ===

* 3030       BREAK
* F000_3030  BREAK2	//Fix32

Trigger a Breakpoint exception.

The BREAK1/2/3 forms overlap with MOV.B, but will be regarded as invalid special cases which will result in an exception rather than a MOV.


=== BSR / JSR ===

* 21dd       BSR		(PC, disp8s)
* 31n1       BSR		(PC, Rn)
* F011_3en0  BSR		(PC, Rn)			//Fix32
* F0dd_Dddd  BSR		(PC, disp20s)		//Fix32

* 32n1       JSR		Rn
* F021_3en0  JSR		Rn					//Fix32

* FEjj_jjjj_F202_CCjj /	BSR		(PC, disp33s)
* FFw0_0ddd_F0dd_Dddd	BSR		(PC, Disp33s)

* FFjj_jjjj_FBjj_jjjj	JSR		Abs48			//Abs48 Call

Branch to subroutine.
The target address is computed and PC is updated to the new address, with the prior value for PC being stored in LR(47:0).

The high order 16 bits of LR will contain saved user flag states:
* LR(63:52) will be copied from SR(15: 4)
* LR(51:50) will be copied from SR(27:26)
* LR(49:48) will be copied from SR( 1: 0)


This instruction is only allowed in Lane 1.


=== BT / JT ===

* 22dd       BT		(PC, disp8s)		//Branch True
* 31n2       BT		(PC, Rn)			//Branch True to PC+(Rn*2)
* F012_3en0  BT		(PC, Rn)			//Fix32
* F0dd_Eddd  BT		(PC, disp20s)		//Branch True, +/- 1MB

* 32n2       JT		Rn
* F022_3en0  JT		Rn					//Fix32

* FFw0_0ddd_F0dd_Eddd  BT	(PC, Disp33s)

Branch if True (SR.T is 1).
The target address is computed and PC is updated to the new address if the condition is met.

This instruction is only allowed in Lane 1.


=== BTRNS ===

* F0nm_1e4C  BTRNS{Q}	Rm, Rn				//(CLZ) Bit Transpose

Bit Transpose. This will transpose the bit pattern in a register such that the LSB of Rm becomes the MSB of Rn, and the MSB of Rm becomes the LSB of Rn.

This will come in both 32 and 64 bit variants.

This instruction is only allowed in Lane 1.


=== CLRS ===

* 3060       CLRS
* F000_3060  CLRS	//Fix32

Clear the SR.S flag.

This instruction is only allowed in Lane 1.


=== CLRT ===

* 3040       CLRT
* F000_3040  CLRT	//Fix32

Clear the SR.T flag.

This instruction is only allowed in Lane 1.


=== CLZ / CTZ ===

* F0nm_1e2C  CLZ{Q}		Rm, Rn		//(CLZ) Count Leading Zeroes
* F0nm_1e3C  CTZ{Q}		Rm, Rn		//(CLZ) Count Trailing Zeroes

Count Leading or Trailing Zeroes.

CLZ will start counting from the MSB.
CTZ will start counting from the LSB.
These will count the number of zeroes until the first non-zero bit is encountered. If the register is zero, then the result will be 32 or 64.

These instructions are only allowed in Lane 1.


=== CMPEQ ===

* 1Cnm       CMPEQ		Rm, Rn
* 2Cnj       CMPEQ		Imm4u, Rn
* 2Dnj       CMPEQ		Imm4n, Rn
* 6Cnj       CMPEQ		Imm4u, Rk
* 6Dnj       CMPEQ		Imm4n, Rk
* F0nm_1gC9  CMPEQ		Rm, Rn			//E.i=0, Update SR.T
* F0nm_1gC9  CMPEQS		Rm, Rn			//E.i=1, Update SR.S (PRED_S)
* F2nC_Cgjj  CMPEQ		Imm9u, Rn
* F2nD_Cgjj  CMPEQ		Imm9n, Rn

Compare if source and destination are Equal.

This provides both zero and one extended immediates, allowing a direct immediate to express values ranging between -16 and 15.


This updates SR.T based on the result of the comparison.
For the 2R form, if E.i is Set, SR.S is updated and SR.T is unchanged.
For the 2RI form, if W.m is Set, SR.S is updated and SR.T is unchanged.
The values of the other bits are unchanged by this operation.

This instruction is only allowed in Lane 1.


=== CMPGE ===

* 1Fnm       CMPGE		Rm, Rn
* 2Fnj       CMPGE		Imm4u, Rn
* 6Fnj       CMPGE		Imm4u, Rk
* F0nm_1gEC  CMPGE		Rm, Rn			//E.i=0, Signed Rn GE Rm
* F0nm_1gEC  CMPGES		Rm, Rn			//E.i=1, Update SR.S (PRED_S)
* F2nA_Cgjj  CMPGE		Imm9u, Rn
* F2nB_Cgjj  CMPGE		Imm9n, Rn

Compare if Rn is Greater or Equal to the immediate.

Only exists for immediates because this can be easily emulated for the two-register forms via swapping the registers and inverting the branch condition.

This updates SR.T based on the result of the comparison.
For the 2R form, if E.i is Set, SR.S is updated and SR.T is unchanged.
For the 2RI form, if W.m is Set, SR.S is updated and SR.T is unchanged.
The values of the other bits are unchanged by this operation.

This instruction is only allowed in Lane 1.


=== CMPGT ===

* 1Enm       CMPGT		Rm, Rn
* 2Enj       CMPGT		Imm4u, Rn
* 6Enj       CMPGT		Imm4u, Rk
* F0nm_1gE9  CMPGT		Rm, Rn			//E.i=0
* F0nm_1gE9  CMPGTS		Rm, Rn			//E.i=1, Update SR.S (PRED_S)
* F2nE_Cgjj  CMPGT		Imm9u, Rn
* F2nF_Cgjj  CMPGT		Imm9n, Rn

Signed Rn GT Rm.

Compare if destination is greater than the source using a signed comparison.

This updates SR.T based on the result of the comparison.
For the 2R form, if E.i is Set, SR.S is updated and SR.T is unchanged.
For the 2RI form, if W.m is Set, SR.S is updated and SR.T is unchanged.
The values of the other bits are unchanged by this operation.

This instruction is only allowed in Lane 1.


=== CMPHI ===

* 1Dnm       CMPHI		Rm, Rn
* F0nm_1gD9  CMPHI		Rm, Rn			//E.i=0
* F0nm_1gD9  CMPHIS		Rm, Rn			//E.i=1, Update SR.S (PRED_S)
* F2n8_Cgjj  CMPHI		Imm9u, Rn
* F2n8_Cgjj  CMPHI		Imm9n, Rn

Unsigned Rn GT Rm.

Compare if destination is greater than the source using an unsigned comparison.

This updates SR.T based on the result of the comparison.
For the 2R form, if E.i is Set, SR.S is updated and SR.T is unchanged.
For the 2RI form, if W.m is Set, SR.S is updated and SR.T is unchanged.
The values of the other bits are unchanged by this operation.

This instruction is only allowed in Lane 1.


=== CMPHS ===

* 36nD       CMPHS		DLR, Rn
* F0nm_1gFC  CMPHS		Rm, Rn			//E.i=0, Unsigned Rn GE Rm
* F0nm_1gFC  CMPHSS		Rm, Rn			//E.i=1, Update SR.S (PRED_S)
* F2n6_Cgjj  CMPHS		Imm9u, Rn
* F2n7_Cgjj  CMPHS		Imm9n, Rn

Unsigned (Rn GE DLR)

Compare if destination is greater than or equal to the source using an unsigned comparison.

This updates SR.T based on the result of the comparison.
For the 2R form, if E.i is Set, SR.S is updated and SR.T is unchanged.
For the 2RI form, if W.m is Set, SR.S is updated and SR.T is unchanged.
The values of the other bits are unchanged by this operation.

This instruction is only allowed in Lane 1.


=== CMPQEQ ===

* 5Fnm       CMPQEQ		Rm, Rn
* F0nm_1GC9  CMPQEQ		Rm, Rn			//E.i=0
* F0nm_1GC9  CMPQEQS	Rm, Rn			//E.i=1, Update SR.S (PRED_S)
* F2nC_CGjj  CMPQEQ		Imm9u, Rn
* F2nD_CGjj  CMPQEQ		Imm9n, Rn

Compare if source and destination are Equal.

This provides both zero and one extended immediates, allowing a direct immediate to express values ranging between -16 and 15.


This updates SR.T based on the result of the comparison.
For the 2R form, if E.i is Set, SR.S is updated and SR.T is unchanged.
For the 2RI form, if W.m is Set, SR.S is updated and SR.T is unchanged.
The values of the other bits are unchanged by this operation.

This instruction is only allowed in Lane 1.


=== CMPQGE ===

* F0nm_1GEC  CMPQGE		Rm, Rn			//E.i=0
* F0nm_1GEC  CMPQGES	Rm, Rn			//E.i=1, Update SR.S (PRED_S)
* F2nA_CGjj  CMPQGE		Imm9u, Rn
* F2nB_CGjj  CMPQGE		Imm9n, Rn

Compare if Rn is Greater or Equal to the immediate.

Only exists for immediates because this can be easily emulated for the two-register forms via swapping the registers and inverting the branch condition.

This updates SR.T based on the result of the comparison.
For the 2R form, if E.i is Set, SR.S is updated and SR.T is unchanged.
For the 2RI form, if W.m is Set, SR.S is updated and SR.T is unchanged.
The values of the other bits are unchanged by this operation.

This instruction is only allowed in Lane 1.


=== CMPQGT ===

* 5Enm       CMPQGT		Rm, Rn
* F0nm_1GE9  CMPQGT		Rm, Rn			//E.i=0
* F0nm_1GE9  CMPQGTS	Rm, Rn			//E.i=1, Update SR.S (PRED_S)
* F2nE_Cejj  CMPQGT		Imm9u, Rn
* F2nF_Cejj  CMPQGT		Imm9n, Rn

Signed Rn GT Rm.

Compare if destination is greater than the source using a signed comparison.

This updates SR.T based on the result of the comparison.
For the 2R form, if E.i is Set, SR.S is updated and SR.T is unchanged.
For the 2RI form, if W.m is Set, SR.S is updated and SR.T is unchanged.
The values of the other bits are unchanged by this operation.

This instruction is only allowed in Lane 1.


=== CMPQHI ===

* 5Dnm       CMPQHI		Rm, Rn
* F0nm_1GD9  CMPQHI		Rm, Rn			//E.i=0
* F0nm_1GD9  CMPQHIS	Rm, Rn			//E.i=1, Update SR.S (PRED_S)
* F2n8_CGjj  CMPQHI		Imm9u, Rn
* F2n8_CGjj  CMPQHI		Imm9n, Rn

Unsigned Rn GT Rm.

Compare if destination is greater than the source using an unsigned comparison.

This updates SR.T based on the result of the comparison.
For the 2R form, if E.i is Set, SR.S is updated and SR.T is unchanged.
For the 2RI form, if W.m is Set, SR.S is updated and SR.T is unchanged.
The values of the other bits are unchanged by this operation.

This instruction is only allowed in Lane 1.


=== CMPQHS ===

* F0nm_1GFC  CMPQHS		Rm, Rn			//E.i=0
* F0nm_1GFC  CMPQHSS	Rm, Rn			//E.i=1, Update SR.S (PRED_S)
* F2n6_CGjj  CMPQHS		Imm9u, Rn
* F2n7_CGjj  CMPQHS		Imm9n, Rn

Unsigned (Rn GE DLR)

Compare if destination is greater than or equal to the source using an unsigned comparison.

This updates SR.T based on the result of the comparison.
For the 2R form, if E.i is Set, SR.S is updated and SR.T is unchanged.
For the 2RI form, if W.m is Set, SR.S is updated and SR.T is unchanged.
The values of the other bits are unchanged by this operation.

This instruction is only allowed in Lane 1.


=== CMPTAxx (TTAG) ===

* F0nm_1gC8  CMPTAEQ	Rm, Rn			//(TTAG) Zx(Rn[59:48]) EQ Rm
* F0nm_1gD8  CMPTAHI	Rm, Rn			//(TTAG) Zx(Rn[59:48]) HI Rm
* F0nm_1gE8  CMPTAHS	Rm, Rn			//(TTAG) Zx(Rn[59:48]) HS Rm

Compare the Tag Attribute Bits for the value in Rn against the reference value in Rm.

The Tag Attribute will be compared as-if it had been zero-extended to 32 bits.


=== CMPTTEQ (TTAG) ===

* F0nm_1GB9  CMPTTEQ	RmImm6u, Rn		//(TTAG)

Compare the Tag-Bits in the immediate with those in Rn:
* 0zzzz0: Rn(63:60)==Imm(4:1)
* 0zzz01: Rn(63:61)==Imm(4:2)
* 0zz011: Rn(63:62)==Imm(4:3)
* 0z0111: Rn(63   )==Imm(4  )
* 1zzzz0: Rn( 3: 0)==Imm(4:1)
* 1zzz01: Rn( 2: 0)==Imm(4:2)
* 1zz011: Rn( 1: 0)==Imm(4:3)
* 1z0111: Rn( 0   )==Imm(4  )


=== CONVFXI / CONVFLI (TTAG) ===

* F0nm_1gF8  CONVFXI	Rm, Rn				//Convert Int64 -> Fixint
* F0nm_1GF8  CONVFLI	Rm, Rn				//Convert Binary64 -> Flonum

The CONVFXI instruction sets the high bits to 01 and copies the low order bits from Rm(61:0).
The CONVFLI instruction sets the high bits to 10 and copies the low order bits from Rm(63:2).


=== CPUID ===

* 36jA       CPUID	Imm4
* F06A_3en0  CPUID	Imm5

Load CPUID bits into DLR.
The immediate gives an index into a table of CPUID bits.

Index 0:
* (63:0): Gives an identifier for the processor.
** 'BJX2xxyy', Identifies core as BJX2.
** 'xx' gives the Baseline ISA Profile and Profile Version.
** 'yy' May give an additional version, or '  ' if absent.

ISA Profiles:
* 'A': Full Profile, 48-bit Address Space, Has WEX3W and Jumbo
* 'B': Fix32 Profile, Has FPU, Optional MMU
* 'C': Basic, 32-bit Address Space.
* 'D': Fix32 Profile, No FPU, Optional MMU
* 'E': Lite Profile, No FPU, Optional MMU, 32-bit Address Space
* 'F': Lite Profile, Has FPU, Optional MMU, 32-bit Address Space
* 'G': Full Profile, 96-bit Address Space, Has WEX3W and Jumbo

This instruction is only allowed in Lane 1.

Index 1:
* (7:0): Logical Core ID
** Gives a logical ID number for the current CPU core.
* (  8): WEX
* (  9): WEX-3W
* ( 10): Jumbo
* ( 11): MMU
* ( 12): Addr48
* ( 13): GSV (64-bit, Packed Integer Ops)
* ( 14): PMORT.x
* ( 15): FPU (GFP)
* ( 16): GSVX (128-Bit FP-SIMD)
* ( 17): GFPX (128-Bit Long-Double Ops)
* ( 18): FMAC (FPU Multiply-Accumulate)
* ( 19): ALUX (128-bit ALU Ops)
* ( 20): XGPR (Set if R32..R63 exist)
* ( 21): PRED_S (Allow SR.S Predicates)
* ( 22): FPU Lane 2 (Allow FPU ops in Lane 2)
* ( 23): Conv FP16 (Packed FP8 and FP16 conversion Ops)
* ( 24): RISC-V Mode
* ( 25): TTAG (Type Tag)
* ( 26): XMOV Addressing
* ( 27): XMOV Quadrant Add Mode
* ( 28): DMAC (Integer Multiply-Accumulate)
* ( 29): Op64 RiMOV
* ( 30): MULQ (64-bit MUL and DIV/MOD instructions)
* ( 31): FDIV (Adds FDIV and FSQRT)

Index 31:
* Hardware Random Number
* Gives a random number generated internally by the CPU.
** Note that this RNG is fully dynamic rather than sequential.
** This RNG is meant to approximate a non-deterministic entropy source.


=== CSELT ===

* F0nm_5go0  CSELT		Rm, Ro, Rn

Select between Rm or Ro based on the value of SR.T, storing the result in Rn.
If SR.T is set, the value from Rm is used, otherwise the value from Ro is used.


=== DIV0 (DIV, Drop) ===

* 30D0      / DIV0
* F000_30D0 / DIV0

Initializes state for unsigned division.

 SR.S <= 0
 SR.T <= 0


=== DIV1 (DIV, Drop) ===

* 30E0      / DIV1
* F000_30E0 / DIV1

Perform a division step, with SR.S and SR.T holding internal state.

 q0 = SR.S;
 t0 = SR.T;
 q1 = DLR[31];
 dn1 = (DLR SHL 1) | t0;
 if (!q0)
   dn2 = dn1 - DHR;
 else
   dn2 = dn1 + DHR;
 c0 = dn2[32];
 q2 = q1 ^ c0;
 t2 = ! q2;
 DLR = dn2;
 SR.S = q2;
 SR.T = t2;
 
 
=== DIVx.Q (3R) ===

* F0nm_6go4 DIVS.Q	Rm, Ro, Rn	//(MULQ) 64-bit Signed Divide
* F0nm_6Go4 DIVU.Q	Rm, Ro, Rn	//(MULQ) 64-bit Unsigned Divide
* F0nm_7go4 DIVS.L	Rm, Ro, Rn	//(MULQ) 32-bit Signed Divide
* F0nm_7Go4 DIVU.L	Rm, Ro, Rn	//(MULQ) 32-bit Unsigned Divide

Perform an integer division.
Divides Rm by Ro and stores the result in Rn.

The Q form performs a 64-bit division, whereas the L form performs a 32-bit division.

Values for 32-bit divide will be required to be in-range, the result of a division with out-of-range values is undefined.

This instruction will be part of the MULQ extension.

This operation only exists in Lane 1.


=== EXTS.B ===

* 32n6       EXTS.B	Rn
* F0nm_1g8C  EXTS.B	Rm, Rn				//Q=0, I=0

Sign extend the value in the low 8 bits of the register to the width of the register.


=== EXTS.L ===

* 36n5       EXTS.L	Rn
* F0nm_1g5C  EXTS.L	Rm, Rn				//Q=0, I=0

Sign extend the value in the low 32 bits of the register to the width of the register.


=== EXTS.W ===

* 32n7       EXTS.W	Rn
* F0nm_1g9C  EXTS.W	Rm, Rn				//Q=0, I=0

Sign extend the value in the low 16 bits of the register to the width of the register.


=== EXTU.B ===

* 32n4       EXTU.B	Rn
* F0nm_1G8C  EXTU.B	Rm, Rn				//Q=1, I=0

Zero extend the value in the low 8 bits of the register to the width of the register.


=== EXTU.L ===

* 36n4       EXTU.L	Rn
* F0nm_1G5C  EXTU.L	Rm, Rn				//Q=1, I=0

Zero extend the value in the low 32 bits of the register to the width of the register.


=== EXTU.W ===

* 32n5       EXTU.W	Rn
* F0nm_1G9C  EXTU.W	Rm, Rn				//Q=1, I=0

Zero extend the value in the low 16 bits of the register to the width of the register.


=== INVxx ===

* 30F2       INVTLB				//Flush the TLB
* 31nC       INVIC	Rn			//Flush L1 I-Cache for Address
* 31nD       INVDC	Rn			//Flush L1 D-Cache for Address
* F002_30F0  INVTLB
* F01C_3en0  INVIC	Rn
* F01D_3en0  INVDC	Rn

Flush or Invalidate parts of the cache.

The INVIC instruction effects the Instruction Cache, whereas INVDC effects the Data Cache.

Invalidating the instruction cache causes any subsequent execution of instructions within the given cache line to be reloaded from memory. This instruction only effects the L1 and its associated state.

The INVIC instruction, as such, is primarily intended for self-modifying code, or to prepare for execution when new code has been loaded into memory (potentially over the top of existing code).


The INVDC instruction will mark cache lines as "flushed" within the L1 data-cache. On subsequent access, they will be written back to L2 if internally marked as dirty, otherwise the corresponding cache lines will be reloaded from the L2 cache.

Doing a proper flush of an address, as such, will involve a process:
  Invalidate the address (to mark it as flushed);
  Load from the address (causing it to be stored back to L2);
  Invalidate the address again (to discard anything just loaded).


If INVIC or INVDC is given an address in the MMIO range, additional special behaviors may be triggered. Using these with FFFFFFFF will cause the whole L1 cache to be flushed.

Passing -2 to INVDC will trigger an L2 Flush. Note that getting something written back from L2 will require first flushing it from the L1.


The INVTLB instruction will flush the TLB. This would be done as part of changing the active page tables.

=== JCMPxx ===

* F1zz_Czzz
** F1nm_Cpdd ? JTSTT	Rm, Rn, disp8s	//(JCMP)
** F1nm_CPdd ? JTSTQT	Rm, Rn, disp8s	//(JCMP)
** F1nm_Cqdd ? JTSTF	Rm, Rn, disp8s	//(JCMP)
** F1nm_CQdd ? JTSTQF	Rm, Rn, disp8s	//(JCMP)
* F1zz_Dzzz
** F1nm_Dpdd ? JCMPGT	Rm, Rn, disp8s	//(JCMP)
** F1nm_DPdd ? JCMPQGT	Rm, Rn, disp8s	//(JCMP)
** F1nm_Dqdd ? JCMPLE	Rm, Rn, disp8s	//(JCMP)
** F1nm_DQdd ? JCMPQLE	Rm, Rn, disp8s	//(JCMP)
* F1zz_Ezzz
** F1nm_Epdd ? JCMPHI	Rm, Rn, disp8s	//(JCMP)
** F1nm_EPdd ? JCMPQHI	Rm, Rn, disp8s	//(JCMP)
** F1nm_Eqdd ? JCMPLS	Rm, Rn, disp8s	//(JCMP)
** F1nm_EQdd ? JCMPQLS	Rm, Rn, disp8s	//(JCMP)
* F1zz_Fzzz
** F1nm_Fpdd ? JCMPEQ	Rm, Rn, disp8s	//(JCMP)
** F1nm_FPdd ? JCMPQEQ	Rm, Rn, disp8s	//(JCMP)
** F1nm_Fqdd ? JCMPNE	Rm, Rn, disp8s	//(JCMP)
** F1nm_FQdd ? JCMPQNE	Rm, Rn, disp8s	//(JCMP)

Compare (Rn op Rm) and branch based on the result.
This operation will only be present if JCMP is present.

Note that LT and GE comparisons may be created by switching the arguments.
Alternately 

TSTT will perform a logical AND, and Branch if the result is Zero.
TSTF will perform a logical AND, and Branch if the result is Not Zero.


=== JCMPZxx ===

* F2n6_Dfjj  JCMPZ{Q}xx		Rn, Disp8s	//(JCMP)
* F2n7_Dfjj  JCMPZ{Q}xx		Rn, Disp8s	//(JCMP)

Compare (Rn op 0) and branch based on the result.

The (Rm(0),Em,Ei) bits will encode the operator:
* 000: EQ (Rn==0)
* 001: NE (Rn!=0)
* 010: LE (Rn<=0), Signed
* 011: GT (Rn> 0), Signed
* 100: LT (Rn< 0), Signed
* 101: GE (Rn>=0), Signed
* 110: -
* 111: -

This operation will only be present if JCMP is present.


=== LDACL ===

* 3042       LDACL
* F002_3040  LDACL

Load DLR into the ACL Cache.

This entry associates a set of access modes with a pair of VUGID keys.
* (15: 0): TLB VUGID	//VUGID from the TLB (ACLID).
* (31:16): KRR VUGID	//VUGID from the KRR.
* (43:32): Access Mode	//Same format as in TLBE.
* (63:44): Reserved

Note that unlike with normal TLBE VUGID matching, the ACL entries will require an exact match for both the TLBE and KRR VUGIDs. In this case, only the User and Mode flags in the Access Mode will be used.

Modes:
* 000: Ignore
* 001: Use 'User' flags if an exact match is found.
* 010: Reserved
* ...
* 111: Reserved

When ACL Checking is used in the TLBE, then the contents of the ACL cache will be matched with the keys in the KRR, and if a match is found, the flags from the matching entry will be used. Failure to find a valid match will result in an ACL Check exception.


=== LDTLB ===

* 30F0       LDTLB
* 3052       LDXTLB			//(XMOV)
* F000_30F0  LDTLB
* F002_3050  LDXTLB			//(XMOV)

Copy DHR:DLR into the TLB.

This instruction form is intended for use in a TLB Miss handler.

This instruction is invalid outside of an ISR. Its behavior is undefined, but should behave like a BREAK.

LDXTLB will be an XMOV variant of LDTLB.
The registers R7:R6:R5:R4 will be loaded as a 256-bit Extended TLB (or XTLB).



=== LDEKRR / LDEKEY / LDEENC / SVEKRR ===

* F002_30A0  SVEKRR		//Save Encoded Keyring
* F002_30C0  LDEKRR		//Load Encoded Keyring
* F002_30D0  LDEKEY		//Load Encoded Key
* F002_30E0  LDEENC		//Encode Key

Load Encoded Keyring Register, or the Key for decoding the Keyring.
Support for these instructions will be Optional, dependent on their ability to be implemented securely.

In both LDEKRR and LDEKEY, DHR:DLR will contain the value to be loaded.

The LDEKRR instruction will decode and load a keyring value into KRR.
This instruction will also check the integrity of the decoded key, raising a fault if the provided key is invalid.

The LDEKEY instruction will load a seed value representing the encryption key into an internal register (which will otherwise be invisible). The key will be a random number to be generated by a sufficiently strong random number generator, with its initial state being undefined.

Loading a key value with the low order bits set to 0 will effectively disable the LDEKRR instruction. The use of LDEKRR will be disabled until LDEKEY is used.


The LDEENC will encode a keyring value from DLR and store the result in DHR:DLR. The value may then be loaded via LDEKRR.

The SVEKRR instruction will encode the current KRR and store it into DHR:DLR.


Of these, only LDEKRR and SVEKRR are to be allowed in user-mode. These instructions are to allow controlled transition between keyrings, and to allow saving and restoring keyrings without exposing their contents to the application, or to allow the application to forge its own keyrings.


Both LDEKEY and LDEENC will be supervisor only.

These instructions may not be used in a WEX sequence.
The specific encoding used will be depend on the implementation.
A key encoded on one machine will not necessarily be valid on a different machine.

Encoded keys should not be placed in memory which is readable from user-mode, as this increases the likelihood of code being able to break the encoding and forge its own keys.


=== LEA.B ===

* 4Cnm       LEA.B		(Rm, DLR), Rn
* F0nm_0Go4  LEA.B		(Rm, Ro), Rn
* F1nm_0Gdd  LEA.B		(Rm, disp9u), Rn

Load the effective address of the Base register added to the displacement and store the result into the destination register.

This will use a scale factor of 1.

Note that the effective precision of LEA will be relative to the size of the address space. The effective precision of a LEA may be smaller than 64 bits.


=== LEA.L ===

* 4Enm       LEA.L	(Rm, DLR), Rn
* F0nm_0Go6  LEA.L	(Rm, Ro), Rn
* F1nm_2Gdd  LEA.L	(Rm, disp9u), Rn

Load the effective address of the Base register added to the scaled displacement and store the result into the destination register.

This will use a scale factor of 4.


=== LEA.Q ===

* 4Fnm       LEA.Q	(Rm, DLR), Rn
* F0nm_0Go7  LEA.Q	(Rm, Ro), Rn
* F1nm_3Gdd  LEA.Q	(Rm, disp9u), Rn

Load the effective address of the Base register added to the scaled displacement and store the result into the destination register.

This will use a scale factor of 8.


=== LEA.W ===

* 4Dnm       LEA.W	(Rm, DLR), Rn
* F0nm_0Go5  LEA.W	(Rm, Ro), Rn
* F1nm_1Gdd  LEA.W	(Rm, disp9u), Rn

Load the effective address of the Base register added to the scaled displacement and store the result into the destination register.

This will use a scale factor of 2.


=== LDIN / LDIZ ===

Targeting R0/DLR:
* Ajjj       LDIZ	Imm12u, DLR
* Bjjj       LDIN	Imm12n, DLR
* FAjj_jjjj	 LDIZ	Imm24u, DLR		//Zero Extend
* FBjj_jjjj	 LDIN	Imm24n, DLR		//One Extend

Targeting GPRs:
* Dnii       LDI		Imm8s, Rn		//Rn=Imm8s
* F2n0_Chjj  LDIZ		Imm10u, Rn		//(WEX2), Rn=Imm10u
* F2n0_CHjj  LDIZD		Imm10u, Rn		//(WEX2), Rn=Imm10u (Hi=Undef)
* F2n1_Chjj  LDIN		Imm10n, Rn		//(WEX2), Rn=Imm10n
* F2n1_CHjj  LDIND		Imm10n, Rn		//(WEX2), Rn=Imm10n (Hi=Undef)
* F80n_iiii  LDIZ		Imm16u, Rn
* F81n_iiii  LDIZ		Imm16u, Rk
* F82n_iiii  LDIN		Imm16n, Rn
* F83n_iiii  LDIN		Imm16n, Rk

* FE-FE F80n_iiii  LDI	Imm64, Rn		//R0 ..R15
* FE-FE F81n_iiii  LDI	Imm64, Rk		//R16..R31
* FE-FE F82n_iiii  LDI	Imm64, Rk		//R32..R47
* FE-FE F83n_iiii  LDI	Imm64, Rk		//R48..R63

Load an 8, 12, or 24 bit value into DLR.
Load an 8, 10, 16, or 32 bit value into a GPR.

LDIZ will zero extend the value up to the size of the register.

LDIN will extend the value with ones up to the size of the register.


=== LDISH ===

* 26jj       LDISH	Imm8u, DLR
* F2n2_Chjj  LDISH	Imm8u, Rn

Load Immediate with Shift.

The value in DLR is shifted left 8 bits, and the immediate value is coppied into the low bits.

The 32-bit encoding is mostly intended for use with WEX2. The high 2 bits of the imm10 field are reserved and must be zero.


=== LDIHI{Q} ===

* F2n3_Chjj  LDIHI	Imm10u, Rn
* F2n3_CHjj  LDIHIQ	Imm10u, Rn

Load High Immediate.

LDIHI will load the immediate into bits (31:22), with the result zero extended.
LDIHIQ will load the immediate into bits (63:54).

If used with a Jumbo Prefix, LDIHI will load a 32 bit immediate into (47:16) and LDIHIQ into (63:32).



=== LDISH16 ===

* F86n_iiii  LDISH16	Imm16u, Rn
* F87n_iiii  LDISH16	Imm16u, Rk

Load Immediate with Shift.

The value in DLR is shifted left 16 bits, and the low bits are set according to the pattern value given.


=== LDIROz{Q} (Possible) ===

* F2n4_Chjj  LDIROZ		Imm10u, Rn
* F2n4_CHjj  LDIROZQ	Imm10u, Rn
* F2n5_Chjj  LDIRON		Imm10n, Rn
* F2n5_CHjj  LDIRONQ	Imm10n, Rn

Load Rotated Immediate.

The high-order bits of the immediate will be rotated-left by a shift given in the low 4 bits.

If E.Q is Clear, then a 32-bit rotate will be used and the value will be shifted by a multiple of 2 bits.

If E.Q is Set, then a 64-bit rotate will be used and the value will be shifted by a multiple of 4 bits.

In a Jumbo64 form, the 33-bit immediate will be interpreted as a 25 bit immediate with an 8 bit unscaled shift. Behavior will otherwise be similar to a normal rotate instruction.

This operation may be limited to Lane 1.


=== LDTEX (LDTEX) ===

* F0nm_0GdB				LDTEX	(Rm, Ro), Rn				//(LDTEX)
* FFw0_0vii-F0nm_0GoB	LDTEX	(Rm, Ro, Disp11u), Rn		//(LDTEX+RiMOV)
* FFw0_0Vii-F0nm_0GoB	LDTEX	(Rm, Ro*Sc, Disp9u), Rn		//(LDTEX+RiMOV)

Load from Texture.

The Rm gives the base address and format of the texture.

Unlike normal Load/Store instructions, Rm will require a 64-bit alignment.
* Note that alignment will still be required even with 16 or 32-bit texels.

The Ro field gives the ST coords, as a pair of 16.16 fixed-point values.
The ST coordinate values will be interpreted as a texel coordinate.

The result texel will be unpacked into RGBA64 form (4x Int16).

The Rm field will be interpreted as:
* (47: 0): Texture Base Address
* (51:48): Texture X Size
* (56:52): Texture Combined Size (X+Y)
* (59:57): Block Mode
* (63:60): Pointer Tag

Texture X Size:
* 0: Interpret texture as Morton Order
** This will interleave the S and T bits, using this as the index.
* 1..12: X Stride of 2 .. 4096 pixels.
** Y will be shifted left by this many bits, with X in the low bits.
** Note that the low 2-bits of S and T will be cut off for block textures.

Texture Combined Size:
* Interpreted as the log2 of a bit-mask for the texture index (in texels).
* Note that the mask effectively discards the low 4 bits for block coordinates.
** The complete mask would be applicable for RGBA textures.
** However, LDTEX is not required to mask the low 4 bits of the coordinate.

Block Mode:
* 000: UTX2
* 001: RGBA64 / RGBA64F
* 010: UTX3 (LDR)
* 011: UTX3 (HDR)
* 100: RGB15F / RGB4_E4 (?)
* 101: RGB555A
* 110: RGBA8 / RGBA32
* 111: RGBA32_FP8U

If a displacement is used, it will be interpreted as additional parameters:
* Disp(2:0): Pixel Selector
** 000: Truncare (Default)
** 001: Round Nearest
** 010: Reserved
** 011: Reserved
** 100: Round S and T downward (Truncate)
** 101: Round S upward, T downward
** 110: Round S downward, T upward
** 111: Round S and T upward


For UTX2, See [BLKUTX2 (RGB)]

For RGB555A, See [RGB Pack/Unpack]

RGB555A:
* 0rrrrrgggggbbbbb, Opaque
* 1rrrraggggabbbba, Translucent (3 bit Alpha)


RGB4_E4:
* (15:12): Exponent
* (11: 8): R
* ( 7: 4): G
* ( 3: 0): B
* This is a joint exponent format with denormal components.


=== MACx.L ===

* F0nm_6go0  MACS.L		Rm, Ro, Rn		//(DMAC) Rn=Sx(Rn+(Rm*Ro))
* F0nm_6Go0  MACS.L		Rm, Imm5u, Rn	//(DMAC) Rn=Sx(Rn+(Rm*Imm))
* F0nm_6go1  MACU.L		Rm, Ro, Rn		//(DMAC) Rn=Zx(Rn+(Rm*Ro))
* F0nm_6Go1  MACU.L		Rm, Imm5u, Rn	//(DMAC) Rn=Zx(Rn+(Rm*Imm))
* F0nm_6go2  DMACS.L	Rm, Ro, Rn		//(DMAC) Rn=Rn+(Rm*Ro)
* F0nm_6Go2  DMACS.L	Rm, Imm5u, Rn	//(DMAC) Rn=Rn+(Rm*Imm)
* F0nm_6go3  DMACU.L	Rm, Ro, Rn		//(DMAC) Rn=Rn+(Rm*Ro)
* F0nm_6Go3  DMACU.L	Rm, Imm5u, Rn	//(DMAC) Rn=Rn+(Rm*Imm)

* FEii_iiii-F0nm_6Gi0  MACS.L	Rm, Imm29s, Rn		//(DMAC) Rn=Sx(Ro+(Rm*Imm))
* FEii_iiii-F0nm_6Gi1  MACU.L	Rm, Imm29s, Rn		//(DMAC) Rn=Zx(Ro+(Rm*Imm))
* FEii_iiii-F0nm_6Gi2  DMACS.L	Rm, Imm29s, Rn		//(DMAC) Rn=Ro+(Rm*Imm)
* FEii_iiii-F0nm_6Gi3  DMACU.L	Rm, Imm29s, Rn		//(DMAC) Rn=Ro+(Rm*Imm)

* FFw0_0Vpp-F0nm_6go0  MACS.L	Rm, Ro, Rp, Rn		//(DMAC) Rn=Sx(Rp+(Rm*Ro))
* FFw0_0Vpp-F0nm_6go1  MACU.L	Rm, Ro, Rp, Rn		//(DMAC) Rn=Zx(Rp+(Rm*Ro))
* FFw0_0Vpp-F0nm_6go2  DMACS.L	Rm, Ro, Rp, Rn		//(DMAC) Rn=Rp+(Rm*Ro)
* FFw0_0Vpp-F0nm_6go3  DMACU.L	Rm, Ro, Rp, Rn		//(DMAC) Rn=Rp+(Rm*Ro)

* FFw0_0vii-F0nm_6Go0  MACS.L	Rm, Imm17s, Rn		//(DMAC) Rn=Sx(Rn+(Rm*Imm))
* FFw0_0vii-F0nm_6Go1  MACU.L	Rm, Imm17s, Rn		//(DMAC) Rn=Zx(Rn+(Rm*Imm))
* FFw0_0vii-F0nm_6Go2  DMACS.L	Rm, Imm17s, Rn		//(DMAC) Rn=Rn+(Rm*Imm)
* FFw0_0vii-F0nm_6Go3  DMACU.L	Rm, Imm17s, Rn		//(DMAC) Rn=Rn+(Rm*Imm)

* FFw0_0Vii-F0nm_6Go0  MACS.L	Rm, Imm11s, Ro, Rn	//(DMAC) Rn=Sx(Ro+(Rm*Imm))
* FFw0_0Vii-F0nm_6Go1  MACU.L	Rm, Imm11s, Ro, Rn	//(DMAC) Rn=Zx(Ro+(Rm*Imm))
* FFw0_0Vii-F0nm_6Go2  DMACS.L	Rm, Imm11s, Ro, Rn	//(DMAC) Rn=Ro+(Rm*Imm)
* FFw0_0Vii-F0nm_6Go3  DMACU.L	Rm, Imm11s, Ro, Rn	//(DMAC) Rn=Ro+(Rm*Imm)


Multiply Accumulate.

The MACS and MACU instructions will do a multiply-accumulate with a 32-bit result being sign or zero extended to 64 bits.

The DMACS and DMACU instructions will multiply two 32-bit quantities and accumulate using a 64-bit result.


=== MODx.Q (3R) ===

* F0nm_6go5  MODS.Q	Rm, Ro, Rn		//(MULQ) 64-bit Signed Modulo
* F0nm_6Go5  MODU.Q	Rm, Ro, Rn		//(MULQ) 64-bit Unsigned Modulo
* F0nm_7go5  MODS.L	Rm, Ro, Rn		//(MULQ) 32-bit Signed Modulo
* F0nm_7Go5  MODU.L	Rm, Ro, Rn		//(MULQ) 32-bit Unsigned Modulo

Perform an integer modulo.
Find the modulo of dividing Rm by Ro and stores the result in Rn.

This instruction will be part of the MULQ extension.

This operation only exists in Lane 1.


=== MOV ===

MOV, GPR
* 18nm       MOV		Rm, Rn
* 19zz       MOV		Rj, Rn
* 1Azz       MOV		Rm, Rk
* 1Bzz       MOV		Rj, Rk
* F0nm_1g89  MOV		Rm, Rn				//Rn=Rm
* F0nm_1G89  MOVX		Xm, Xn				//(MOVX2)
* F0nm_1G5C  MOVD		Rm, Rn				//(Pseudo) EXTU.L

MOV, Control Register
* 48nm       MOV		Rm, Cn
* 49nm       MOV		Cm, Rn
* 4Anm       MOV		Rm, Sn
* 4Bnm       MOV		Sm, Rn
* F0nm_1eA9  MOV		Rm, Cn				//Cn=Rm
* F0nm_1eB9  MOV		Cm, Rn				//Rn=Cm
* F0nm_1eAC  MOV		Rm, Sn				//Cn=Rm
* F0nm_1eBC  MOV		Sm, Rn				//Rn=Cm

Move a value from the source to the destination register.

MOVX will move a 128 bit register pair, and will reuse the old MOVD encoding.

The MOVD instruction is now an alias for the EXTU.L instruction.


=== MOV.B ===

* 00nm       MOV.B		Rn, (Rm)
* 04nm       MOV.B		Rn, (Rm, DLR)		//(Rn==0): PC-Rel
* 08nm       MOV.B		(Rm), Rn
* 0Cnm       MOV.B		(Rm, DLR), Rn		//(Rm==0): PC-Rel
* F0nm_0go4  MOV.B		Rn, (Rm, Ro)		//Q=0	//(Rn==0): PC-Rel
* F0nm_0goC  MOV.B		(Rm, Ro), Rn		//Q=0	//(Rm==0): PC-Rel
* F1nm_0gdd  MOV.B		Rn, (Rm, disp9u)
* F1nm_8gdd  MOV.B		(Rm, disp9u), Rn

* F0nm_0go4  MOV.B		Rn, (Rm, Ro)		//Q=0	//(Rn==0): PC-Rel
* F0nm_0goC  MOV.B		(Rm, Ro), Rn		//Q=0	//(Rm==0): PC-Rel

* FEdd_dddd-F1nm_0gdd  MOV.B	Rn, (Rm, disp33s)			//(Jumbo)
* FEdd_dddd-F1nm_8gdd  MOV.B	(Rm, disp33s), Rn			//(Jumbo)

* FFw0_0vii-F0nm_0gi0  MOV.B	Rn, (Rm, Disp17s)			//(RiMOV)
* FFw0_0vii-F0nm_0go4  MOV.B	Rn, (Rm, Ro, Disp11u)		//(RiMOV)
* FFw0_0Vii-F0nm_0go4  MOV.B	Rn, (Rm, Ro*Sc, Disp9u)		//(RiMOV)
* FFw0_0vii-F0nm_0gi8  MOV.B	(Rm, Disp17s), Rn			//(RiMOV)
* FFw0_0vii-F0nm_0goC  MOV.B	(Rm, Ro, Disp11u), Rn		//(RiMOV)
* FFw0_0Vii-F0nm_0goC  MOV.B	(Rm, Ro*Sc, Disp9u), Rn		//(RiMOV)

Load or store a Byte to/from memory.
The byte is sign extended to the size of the register.


=== MOV.C ===

* F0nm_4go3  MOV.C		Cn, (Rm, Ro)
* F0nm_4goB  MOV.C		(Rm, Ro), Cn
* F1nm_5gdd  MOV.C		Cn, (Rm, disp9u)
* F1nm_7gdd  MOV.C		(Rm, disp9u), Cn

* FEdd_dddd-F1nm_5gdd  MOV.C	Rn, (Rm, disp33s)			//(Jumbo)
* FEdd_dddd-F1nm_7gdd  MOV.C	(Rm, disp33s), Rn			//(Jumbo)

* FFw0_0vii-F0nm_4go3  MOV.C	Rn, (Rm, Ro, Disp11u)		//(RiMOV)
* FFw0_0Vii-F0nm_4go3  MOV.C	Rn, (Rm, Ro*Sc, Disp9u)		//(RiMOV)
* FFw0_0vii-F0nm_4goB  MOV.C	(Rm, Ro, Disp11u), Rn		//(RiMOV)
* FFw0_0Vii-F0nm_4goB  MOV.C	(Rm, Ro*Sc, Disp9u), Rn		//(RiMOV)

Load or store a Control Register to/from memory.
The behavior of this operation will be similar to a MOV.Q, just applying to control registers.


=== MOV.L ===

* 02nm       MOV.L		Rn, (Rm)
* 06nm       MOV.L		Rn, (Rm, DLR)		//(Rn==0): PC-Rel
* 0Anm       MOV.L		(Rm), Rn
* 0Enm       MOV.L		(Rm, DLR), Rn		//(Rm==0): PC-Rel
* 40nd       MOV.L		Rn, (SP, disp4u)	//Stack-Relative Store
* 42nd       MOV.L		Rk, (SP, disp4u)	//Stack-Relative Store
* 44nd       MOV.L		(SP, disp4u), Rn	//Stack-Relative Load
* 46nd       MOV.L		(SP, disp4u), Rk	//Stack-Relative Load
* F0nm_0go6  MOV.L		Rn, (Rm, Ro)		//(Rn==0): PC-Rel
* F0nm_0goE  MOV.L		(Rm, Ro), Rn		//(Rm==0): PC-Rel
* F1nm_2gdd  MOV.L		Rn, (Rm, disp9u)
* F1nm_Agdd  MOV.L		(Rm, disp9u), Rn

* FEdd_dddd-F1nm_2gdd  MOV.L	Rn, (Rm, disp33s)			//(Jumbo)
* FEdd_dddd-F1nm_Agdd  MOV.L	(Rm, disp33s), Rn			//(Jumbo)

* FFw0_0vii-F0nm_0gi2  MOV.L	Rn, (Rm, Disp17s)			//(RiMOV)
* FFw0_0Vii-F0nm_0gi2  MOV.L	Rn, (Rm, Disp17s*1)			//(RiMOV)
* FFw0_0vii-F0nm_0go6  MOV.L	Rn, (Rm, Ro, Disp11u)		//(RiMOV)
* FFw0_0Vii-F0nm_0go6  MOV.L	Rn, (Rm, Ro*Sc, Disp9u)		//(RiMOV)
* FFw0_0vii-F0nm_0giA  MOV.L	(Rm, Disp17s), Rn			//(RiMOV)
* FFw0_0Vii-F0nm_0giA  MOV.L	(Rm, Disp17s*1), Rn			//(RiMOV)
* FFw0_0vii-F0nm_0goE  MOV.L	(Rm, Ro, Disp11u), Rn		//(RiMOV)
* FFw0_0Vii-F0nm_0goE  MOV.L	(Rm, Ro*Sc, Disp9u), Rn		//(RiMOV)

Load or store a DWord to/from memory.

Thought: This is a stupid number of MOV.L forms, it may be relevant to prune some of them.

For example, F0-28 and F1-2 could both achieve a similar purpose, so don't need to both exist in the case of SP. The Disp9 cases don't save much on average vs disp17s when F0-28 exists, but save a bit more if it does not exist.


=== MOV.Q ===

* 03nm       MOV.Q		Rn, (Rm)
* 07nm       MOV.Q		Rn, (Rm, DLR)
* 0Bnm       MOV.Q		(Rm), Rn
* 0Fnm       MOV.Q		(Rm, DLR), Rn
* 41nd       MOV.Q		Rn, (SP, disp4u)
* 43nd       MOV.Q		Rk, (SP, disp4u)
* 45nd       MOV.Q		(SP, disp4u), Rn
* 47nd       MOV.Q		(SP, disp4u), Rk
* F0nm_0go7  MOV.Q		Rn, (Rm, Ro)
* F0nm_0goF  MOV.Q		(Rm, Ro), Rn
* F1nm_3gdd  MOV.Q		Rn, (Rm, disp9u)
* F1nm_Bgdd  MOV.Q		(Rm, disp9u), Rn

* FEdd_dddd-F1nm_3gdd  MOV.Q	Rn, (Rm, disp33s)			//(Jumbo)
* FEdd_dddd-F1nm_Bgdd  MOV.Q	(Rm, disp33s), Rn			//(Jumbo)

* FFw0_0vii-F0nm_0gi3  MOV.Q	Rn, (Rm, Disp17s)			//(RiMOV)
* FFw0_0Vii-F0nm_0gi3  MOV.Q	Rn, (Rm, Disp17s*1)			//(RiMOV)
* FFw0_0vii-F0nm_0go7  MOV.Q	Rn, (Rm, Ro, Disp11u)		//(RiMOV)
* FFw0_0Vii-F0nm_0go7  MOV.Q	Rn, (Rm, Ro*Sc, Disp9u)		//(RiMOV)
* FFw0_0vii-F0nm_0giB  MOV.Q	(Rm, Disp17s), Rn			//(RiMOV)
* FFw0_0Vii-F0nm_0giB  MOV.Q	(Rm, Disp17s*1), Rn			//(RiMOV)
* FFw0_0vii-F0nm_0goF  MOV.Q	(Rm, Ro, Disp11u), Rn		//(RiMOV)
* FFw0_0Vii-F0nm_0goF  MOV.Q	(Rm, Ro*Sc, Disp9u), Rn		//(RiMOV)

Load or store a QWord to/from memory.


=== MOV.W ===

* 01nm       MOV.W		Rn, (Rm)
* 05nm       MOV.W		Rn, (Rm, DLR)
* 09nm       MOV.W		(Rm), Rn
* 0Dnm       MOV.W		(Rm, DLR), Rn
* F0nm_0go5  MOV.W		Rn, (Rm, Ro)
* F0nm_0goD  MOV.W		(Rm, Ro), Rn
* F1nm_1gdd  MOV.W		Rn, (Rm, disp9u)
* F1nm_9gdd  MOV.W		(Rm, disp9u), Rn

* FEdd_dddd-F1nm_1gdd  MOV.W	Rn, (Rm, disp33s)			//(Jumbo)
* FEdd_dddd-F1nm_9gdd  MOV.W	(Rm, disp33s), Rn			//(Jumbo)

* FFw0_0vii-F0nm_0gi1  MOV.W	Rn, (Rm, Disp17s)			//(RiMOV)
* FFw0_0Vii-F0nm_0gi1  MOV.W	Rn, (Rm, Disp17s*1)			//(RiMOV)
* FFw0_0vii-F0nm_0go5  MOV.W	Rn, (Rm, Ro, Disp11u)		//(RiMOV)
* FFw0_0Vii-F0nm_0go5  MOV.W	Rn, (Rm, Ro*Sc, Disp9u)		//(RiMOV)
* FFw0_0vii-F0nm_0gi9  MOV.W	(Rm, Disp17s), Rn			//(RiMOV)
* FFw0_0Vii-F0nm_0gi9  MOV.W	(Rm, Disp17s*1), Rn			//(RiMOV)
* FFw0_0vii-F0nm_0goD  MOV.W	(Rm, Ro, Disp11u), Rn		//(RiMOV)
* FFw0_0Vii-F0nm_0goD  MOV.W	(Rm, Ro*Sc, Disp9u), Rn		//(RiMOV)

Load or store a Word to/from memory.
The Word value is sign extended to the size of the register.


=== MOVU.B ===

* 50nm       MOVU.B	(Rm), Rn
* 52nm       MOVU.B	(Rm, DLR), Rn
* F0nm_0GoC  MOVU.B	(Rm, Ro), Rn
* F1nm_8Gdd  MOVU.B	(Rm, disp9u), Rn

* FEdd_dddd-F1nm_8Gdd  MOVU.B	(Rm, disp33s), Rn			//(Jumbo)

* FFw0_0vii-F0nm_0Gi8  MOVU.B	(Rm, Disp17s), Rn			//(RiMOV)
* FFw0_0vii-F0nm_0GoC  MOVU.B	(Rm, Ro, Disp11u), Rn		//(RiMOV)
* FFw0_0Vii-F0nm_0GoC  MOVU.B	(Rm, Ro*Sc, Disp9u), Rn		//(RiMOV)

Load or store a Byte to/from memory.
The byte is zero extended to the size of the register.


=== MOVU.L ===

* 28nd       MOVU.L	(SP, disp4u), Rn
* 2And       MOVU.L	(SP, disp4u), Rk
* 80nm       MOVU.L	(Rm), Rn
* 88nm       MOVU.L	(Rm, DLR), Rn
* F0nm_0GoE  MOVU.L	(Rm, Ro), Rn
* F1nm_AGdd  MOVU.L	(Rm, disp9u), Rn

* FEdd_dddd-F1nm_AGdd  MOVU.L	(Rm, disp33s), Rn			//(Jumbo)

* FFw0_0vii-F0nm_0GiA  MOVU.L	(Rm, Disp17s), Rn			//(RiMOV)
* FFw0_0Vii-F0nm_0GiA  MOVU.L	(Rm, Disp17s*1), Rn			//(RiMOV)
* FFw0_0vii-F0nm_0GoE  MOVU.L	(Rm, Ro, Disp11u), Rn		//(RiMOV)
* FFw0_0Vii-F0nm_0GoE  MOVU.L	(Rm, Ro*Sc, Disp9u), Rn		//(RiMOV)

Load or store a DWord to/from memory.
The byte is zero extended to the size of the register.


=== MOVU.W ===

* 51nm       MOVU.W	(Rm), Rn
* 53nm       MOVU.W	(Rm, DLR), Rn
* F0nm_0GoD  MOVU.W	(Rm, Ro), Rn
* F1nm_9Gdd  MOVU.W	(Rm, disp9u), Rn

* FEdd_dddd-F1nm_9Gdd  MOVU.W	(Rm, disp33s), Rn			//(Jumbo)

* FFw0_0vii-F0nm_0Gi9  MOVU.W	(Rm, Disp17s), Rn			//(RiMOV)
* FFw0_0Vii-F0nm_0Gi9  MOVU.W	(Rm, Disp17s*1), Rn			//(RiMOV)
* FFw0_0vii-F0nm_0GoD  MOVU.W	(Rm, Ro, Disp11u), Rn		//(RiMOV)
* FFw0_0Vii-F0nm_0GoD  MOVU.W	(Rm, Ro*Sc, Disp9u), Rn		//(RiMOV)

Load or store a Word to/from memory.
The word is zero extended to the size of the register.


=== MOV.X (MOVX2) ===

* 29nd       MOV.X		(SP, disp4u), Rx
* 2Bnd       MOV.X		Rx, (SP, disp4u)
* F0nm_4eo0 ? MOV.X		Rn, (Rm, Disp5)
* F0nm_4eo4  MOV.X		Rn, (Rm, Ro)
* F0nm_4eo8 ? MOV.X		(Rm, Disp5), Rn
* F0nm_4eoC  MOV.X		(Rm, Ro), Rn
* F1nm_5Gdd  MOV.X		Rn, (Rm, disp9u)
* F1nm_7Gdd  MOV.X		(Rm, disp9u), Rn

* FEdd_dddd-F1nm_5gdd  MOV.X	Rn, (Rm, disp33s)			//(Jumbo)
* FEdd_dddd-F1nm_7gdd  MOV.X	(Rm, disp33s), Rn			//(Jumbo)

* FFw0_0vii-F0nm_4gi0  MOV.X	Rn, (Rm, Disp17s)			//(RiMOV)
* FFw0_0vii-F0nm_4go4  MOV.X	Rn, (Rm, Ro, Disp11u)		//(RiMOV)
* FFw0_0Vii-F0nm_4go4  MOV.X	Rn, (Rm, Ro*Sc, Disp9u)		//(RiMOV)
* FFw0_0vii-F0nm_4gi8  MOV.X	(Rm, Disp17s), Rn			//(RiMOV)
* FFw0_0vii-F0nm_4goC  MOV.X	(Rm, Ro, Disp11u), Rn		//(RiMOV)
* FFw0_0Vii-F0nm_4goC  MOV.X	(Rm, Ro*Sc, Disp9u), Rn		//(RiMOV)

Load or Store a 128-bit Register Pair.
Register pair is Even/Odd, and the target memory address is required to have an 8 byte alignment.

Note that MOV.X will scale the index by 8, rather than by 16. In this sense, it can be thought of more as a pair of QWORD values than as a combined 128-bit value.

As with other MOV.x ops, encodings using PC or GBR as a base will use a byte scale, however, the destination is still required to be aligned.

The results of trying to load or store using a misaligned address are undefined.


=== MOVTT (TTAG) ===

* F0nm_3go1            MOVTT	Rm, Ri, Rn		//(TTAG) Set High 16
* F0nm_3Go1            MOVTT	Rm, Imm5u, Rn	//(TTAG) Set Type-Tag
* FFw0_0Vii_F0nm_3Gi1  MOVTT	Rm, Imm17s, Rn	//(TTAG) Set High 16
* FFw0_iiii_F84n_iiii  XMOVTT	Imm32u, Xn		//(TTAG+XGPR) WMI==11

In the 3R form, this copies the low 48 bits from Rm, and the high 16 from Ri.

In the 3RI Imm5u form, the tag is twiddled:
* zzzz0: Rn(63:60)=Imm(4:1)
* zzz01: Rn(63:61)=Imm(4:2)
* zz011: Rn(63:62)=Imm(4:3)
* z0111: Rn(63   )=Imm(4  )

With the 3RI form, all other bits are copied unchanged from Rm.


XMOVTT will load the 32-bit immediate into the high 16 bits of each target register, with the low half into the low register and the high half into the high register. The remaining 96 bits are kept unchanged.


=== MULx (3R) ===

* 5Anm       MULS	Rm, DLR, Rn
* F0nm_1go2  MULS	Rm, Ro, Rn
* F0nm_1go3  MULU	Rm, Ro, Rn
* F2nm_2gjj  MULS	Rm, Imm9u, Rn
* F2nm_2Gjj  MULU	Rm, Imm9u, Rn

Performs a narrow multiply (32 bit).
Only the low 32 bits are used from the input registers, and the resulting value is 32-bit sign or zero extended.

This operation only exists in Lane 1.


=== MULx.Q (3R) ===

* F0nm_1Go2  MULS.Q		Rm, Ro, Rn			//(MULQ) Signed Multiply
* F0nm_1Go3  MULU.Q		Rm, Ro, Rn			//(MULQ) Unsigned Multiply

Perform a 64-bit multiply, either signed or unsigned.

This instruction will be part of the MULQ extension.

This operation only exists in Lane 1.


=== MULHx.x (3R) ===

* F0nm_3go4  MULHS.Q	Rm, Ro, Rn		//(MULQ) MUL, High Results Signed
* F0nm_3go5  MULHU.Q	Rm, Ro, Rn		//(MULQ) MUL, High Results Unsigned

Perform a 64-bit multiply, keeping the high-order results (bits 127:64 of a widening multiply).

This instruction will be part of the MULQ extension.

This operation only exists in Lane 1.


=== MULx.x (3R) ===

* F0nm_5go2  DMULS.L	Rm, Ro, Rn			//(MULL) Sx 32b Mul (32*32->64)
* F0nm_5go3  DMULU.L	Rm, Ro, Rn			//(MULL) Zx 32b Mul (32*32->64)
* F0nm_5goE  MULS.W		Rm, Ro, Rn			//(MULW) Sx 16b Mul (16*16->32)
* F0nm_5GoE  MULS.W		Rm, Imm5u, Rn		//(MULW) Sx 16b Mul (16*16->32)
* F0nm_5goF  MULU.W		Rm, Ro, Rn			//(MULW) Zx 16b Mul (16*16->32)
* F0nm_5GoF  MULU.W		Rm, Imm5u, Rn		//(MULW) Zx 16b Mul (16*16->32)

These produce widening multiplies of a given input size.
The values in Rm and Ro are multiplied, and the result is stored in Rn.

The WORD multiplies will exist in all lanes.


=== MULx.X (2R) ===

* F0nm_1G48  MULU.X		Xm, Xn				//(MULX) Xn=Xn*Xm
* F0nm_1G58  MULHU.X	Xm, Xn				//(MULX) Xn=(Xn*Xm)>>128


Multiply two 128 bit values, producing a 128-bit result.
* MULU.X will produce a result containing the low-order bits.
* MULHU.X will produce a result containing the high-order bits.



=== NEG ===

* 33n1       NEG	Rn
* 33nC       NEG	Rn, DLR
* F0nm_1e1C  NEG	Rm, Rn				//Rn=(~Rn)+1

Rn=(~Rn)+1

Negate the value in Rn.


=== NEGC ===

* 33n2	NEGC	Rn

Rn=(~Rn)+(!SR.T).

Negate value in Rn and subtract the SR.T flag.
The value of SR.T is updated to reflect the borrow status of the bit.

This operation is only valid in Lane 1.


=== NOP ===

* 3000       NOP
* F000_3000  NOP		//Fix32

Does Nothing.


=== NOT ===

* 33n0       NOT	Rn
* F0nm_1e0C  NOT	Rm, Rn				//Rn=~Rn

Rn=~Rn

Perform a bitwise NOT of the value in Rn.


=== NOTS ===

* 3090       NOTS
* F000_3090  NOTS		//Fix32

SR.S=!SR.S

Invert the SR.S flag.

This operation is only valid in Lane 1.


=== NOTT ===

* 3080       NOTT
* F000_3080  NOTT		//Fix32

SR.T=!SR.T

Invert the SR.T flag.

This operation is only valid in Lane 1.


=== OR ===

* 16nm       OR	Rm, Rn
* 5Bnm       OR	Rm, DLR, Rn
* F0nm_1go6  OR	Rm, Ro, Rn
* F0nm_1e69  OR	Rm, Rn
* F2nm_6gjj  OR	Rm, Imm9u, Rn

Perform a bitwise OR of the source and destination, storing the result in the destination.


=== PMORT.x ===

* F0nm_1g1E ? PMORT.L	Rm, Rn		//(GSV)
* F0nm_1G1E ? PMORT.Q	Rm, Rn		//(GSV)

Packed Morton Shuffle.

Interprets a pair of packed DWORD values as indices and performs a bit shuffle, leading to an index in Morton Order.

The PMORT.Q operation will produce a 64-bit value containing all 32 bits from each index. PMORT.L will produce a 32-bit output which only retains the high 16 bits of each input (essentially the high 32 bits of the 64-bit output).

As a simplified example, if we have two 8 bit values:
* u7,u6,u5,u4,u3,u2,u1,u0 and v7,v6,v5,v4,v3,v2,v1,v0
Then this will produce as output:
* u7,v7,u6,v6,u5,v5,u4,v4,u3,v3,u2,v2,u1,v1,u0,v0


=== ROTCL ===

* F036_3gn0  ROTCL.L	Rn
* F036_3Gn0  ROTCL.Q	Rn

Rn'=(Rn SHL 1)|SR.T; SR.T=MSB

Rotate the value in Rn left by 1 bit, pulling SR.T into the LSB, and putting the shifted out bit into SR.T.

This operation is only valid in Lane 1.


=== ROTCR ===

* F037_3gn0  ROTCR.L	Rn
* F037_3Gn0  ROTCR.Q	Rn

Rotate the value in Rn right by 1 bit, pulling SR.T into the MSB, and putting the shifted out bit into SR.T.

This operation is only valid in Lane 1.


=== ROTL ===

* F034_3en0 ? ROTL		Rn

Rn=(Rn SHL 1)|(Rn SHR 31)

Rotate the value in Rn left by 1 bit.

This operation is only valid in Lane 1.


=== ROTR ===

* F035_3en0 ? ROTR		Rn

Rn=(Rn SHR 1)|(Rn SHL 31)

Rotate the value in Rn right by 1 bit.

This operation is only valid in Lane 1.


=== ROTL (3R) ===

* F0nm_3go2  ROTL.Q		Rm, Ro, Rn		//(ALU) Rotate Left (64b)
* F0nm_3go6  ROTL.L		Rm, Ro, Rn		//(ALU) Rotate Left (32b)
* F0nm_3Go6  ROTLX		Xm, Ro, Xn		//(ALUX) Rotate Left (128b)

Rotate the value in Rn left by Ro.

This operation is only valid in Lane 1.


=== ROTR (3R) ===

** F0nm_3go3  ROTR.Q	Rm, Ro, Rn		//(ALU) Rotate Right (64b)

Rotate the value in Rn right by Ro.

This operation is only valid in Lane 1.


=== RTE ===

* 30C0       RTE
* F000_30C0  RTE	//Fix32

Return from exception.

Initiates the behavior for returning from an exception handler (described elsewhere).


=== RTS / RTSU ===

* 3010       RTS
* 3012       RTSU
* F000_3010  RTS	//Fix32
* F002_3010  RTSU	//Fix32

Return from Subroutine.
This effectively restores the value from LR into PC, transferring control back to LR.

RTSU will be functionally equivalent to RTS with the main exception that LR may not have been modified within an implementation-dependent number of instructions (based on the number of instructions which may be "in-flight" in the processor's execution pipeline). This is to allow the instruction to be treated like a direct unconditional branch. The result of modifying LR within the pipeline is undefined.

With RTS, the branch predictor may treat it as a predicted branch.

The high order 16 bits of LR will contain saved user flag states:
* LR(63:52) will be copied to SR(15: 4)
* LR(51:50) will be copied to SR(27:26)
* LR(49:48) will be copied to SR( 1: 0)


=== SBB ===

* 13nm       SBB	Rm, Rn
* F0nm_1e39  SBB	Rm, Rn

Rn=Rn+(~Rm)+(!SR.T)

Subtract with Borrow.
SR.T is updated with the borrow result of this operation.

WEX: SBB will only update SR.T in Lane 1. If an SBB is in another lane, the state of SR.T will be undefined following the operation.



=== SETS ===

* 3070       SETS
* F000_3070  SETS		//Fix32

Set the SR.S flag.


=== SETT ===

* 3050       SETT
* F000_3050  SETT		//Fix32

Set the SR.T flag.


=== SETTRAP ===

* F0nm_1GA9  SETTRAP	Rn, (Rm)

Optional Debug Feature: Set Tripwire Mode
This modifies the status of the pointed-to cache line, such as setting it to be temporarily write protected.

The Rm pattern will encode the desired mode:
* (3:1): Properties to modify (RXW)
* (  0): Set (Disable Access) or Clear (Enable Access)

Accessing the cache line in a way inconsistent with the current mode may cause a fault.

Setting a tripwire may also optionally trap if an attempt is made to address across the tripwire for sake of a given access type, treating it as a memory boundary.


Note that this feature is optional and intended for debugging, as such:
* It may be treated as NO-OP;
* The effects may be transient and forgotten at any point.
* It may only be used disallow access to a piece of memory.


=== SHAD ===

* F0nm_1g6C  SHAD	Rm, Rn
* F0nm_5go4  SHAD	Rm, Ro, Rn
* F2nm_8pjj  SHAD	Rm, Imm9, Rn

Barrel Shift, Arithmetic.
Operates on a 32-bit value.
The input is 32-bit sign extended prior to performing the shift.

The Shift Value will behave as if it were a sign-extended byte. Positive values will encode left-shifts whereas negative values will encode right shifts.

For SHAD, the shift will be 32-bit modular.

This is allowed in Lanes 1 and 2, Support in Lane 3 is Optional.


=== SHADQ ===

* F0nm_1G6C  SHADQ		Rm, Rn
* F0nm_5Go4  SHADQ		Rm, Ro, Rn
* F2nm_8Pjj  SHADQ		Rm, Imm9, Rn

Barrel Shift, Arithmetic.
Operates on a 64-bit value.

The Shift Value will behave as if it were a sign-extended byte. Positive values will encode left-shifts whereas negative values will encode right shifts.

For SHADQ, the shift will be 64-bit modular.

This is allowed in Lanes 1 and 2, Support in Lane 3 is Optional.


=== SHADX ===

* F0nm_3Go4  SHADX		Xm, Ro, Xn		//(ALUX) Shift Arithmetic (128b)

Barrel Shift, Arithmetic.
Operates on a 128-bit value.

The Shift Value will behave as if it were a sign-extended byte. Positive values will encode left-shifts whereas negative values will encode right shifts.


=== SHLD ===

* F0nm_1g7C  SHLD	Rm, Rn
* F0nm_5go5  SHLD	Rm, Ro, Rn
* F2nm_9pjj  SHLD	Rm, Imm9u, Rn

Barrel Shift, Logical.
Operates on a 32-bit value.
The input is 32-bit zero extended prior to performing the shift.

The Shift Value will behave as if it were a sign-extended byte. Positive values will encode left-shifts whereas negative values will encode right shifts.

For SHLD, the shift will be 32-bit modular.

This is allowed in Lanes 1 and 2, Support in Lane 3 is Optional.


=== SHLDQ ===

* F0nm_1G7C  SHLDQ		Rm, Rn
* F0nm_5Go5  SHLDQ		Rm, Ro, Rn
* F2nm_9Pjj  SHLDQ		Rm, Imm9u, Rn

Barrel Shift, Logical.
Operates on a 64-bit value.

The Shift Value will behave as if it were a sign-extended byte. Positive values will encode left-shifts whereas negative values will encode right shifts.

For SHLD.Q, the shift will be 64-bit modular.

This is allowed in Lanes 1 and 2, Support in Lane 3 is Optional.


=== SHLDX ===

* F0nm_3Go5  SHLDX		Xm, Ro, Xn		//(ALUX) Shift Logical (128b)

Barrel Shift, Logical.
Operates on a 128-bit value.

The Shift Value will behave as if it were a sign-extended byte. Positive values will encode left-shifts whereas negative values will encode right shifts.


=== SHAR ===

* F0nm_2go2  SHAR	Rm, Ro, Rn
* F2nm_8pjj  SHAD	Rm, -Imm9, Rn

Barrel Shift, Arithmetic Right.
Operates on a 32-bit value.
The input is 32-bit sign extended prior to performing the shift.

Positive values will correspond to a right shift, whereas negative values will be undefined. The immediate form will be encoded by inverting the sign.

For SHAR, the shift will be 32-bit modular.

This is allowed in Lanes 1 and 2, Support in Lane 3 is Optional.


=== SHARQ ===

* F0nm_2Go2  SHARQ		Rm, Ro, Rn
* F2nm_8Pjj  SHADQ		Rm, -Imm9, Rn

Barrel Shift, Arithmetic Right.
Operates on a 64-bit value.

The Shift Value will behave as if it were a sign-extended byte. Positive values will encode left-shifts whereas negative values will encode right shifts.

Positive values will correspond to a right shift, whereas negative values will be undefined. The immediate form will be encoded by inverting the sign.

For SHADQ, the shift will be 64-bit modular.

This is allowed in Lanes 1 and 2, Support in Lane 3 is Optional.


=== SHARX ===

* F0nm_3Go2  SHARX		Xm, Ro, Xn		//(ALUX) Shift Arithmetic (128b)

Barrel Shift, Arithmetic Right.
Operates on a 128-bit value.

The Shift Value will behave as if it were a sign-extended byte. Positive values will encode left-shifts whereas negative values will encode right shifts.

Positive values will correspond to a right shift, whereas negative values will be undefined. The immediate form will be encoded by inverting the sign.


=== SHLR ===

* F0nm_2go3  SHLR	Rm, Ro, Rn
* F2nm_9pjj  SHLD	Rm, -Imm9, Rn

Barrel Shift, Logical Right.
Operates on a 32-bit value.
The input is 32-bit zero extended prior to performing the shift.

Positive values will correspond to a right shift, whereas negative values will be undefined. The immediate form will be encoded by inverting the sign.

For SHLR, the shift will be 32-bit modular.

This is allowed in Lanes 1 and 2, Support in Lane 3 is Optional.


=== SHLRQ ===

* F0nm_2Go3  SHLRQ		Rm, Ro, Rn
* F2nm_9Pjj  SHLDQ		Rm, -Imm9, Rn

Barrel Shift, Logical Right.
Operates on a 64-bit value.

Positive values will correspond to a right shift, whereas negative values will be undefined. The immediate form will be encoded by inverting the sign.

For SHLRQ, the shift will be 64-bit modular.

This is allowed in Lanes 1 and 2, Support in Lane 3 is Optional.


=== SHLRX ===

* F0nm_3Go3  SHLRX		Xm, Ro, Xn		//(ALUX) Shift Logical (128b)

Barrel Shift, Logical Right.
Operates on a 128-bit value.

Positive values will correspond to a right shift, whereas negative values will be undefined. The immediate form will be encoded by inverting the sign.


=== SLEEP ===

* 3020       SLEEP
* F000_3020  SLEEP		//Fix32

Causes the processor to sleep until the next interrupt.

May generate an fault if used in a context where this would halt the processor indefinitely.


=== SNIPExx ===

* F0nm_1gB8  SNIPEDC	Rm, Rn		//Calculate L1 D$ Snipe Address
* F0nm_1GB8  SNIPEIC	Rm, Rn		//Calculate L1 I$ Snipe Address

For the address given in Rm, calculate a "sniper" address within the ZERO or RTS pages. These instructions assume either physical memory mapping, or that these pages are identity mapped.

Accessing the address returned by these SNIPEDC will evict whatever was in the cache-line pointed to by Rm from the L1 D-Cache.

Calling to the address returned by SNIPEIC will evict whatever was in this location in the L1 I-Cache.

These operations will only work for direct-mapped caches.


The SNIPExx instructions will generate a NULL result if SNIPExx is not valid (such as due to using an associative cache). In this case, an INVDC or INVIC cache-flush process will be required instead.


=== SRTTWID (?) ===

* 36nB       SRTTWID	Imm4
* F06B_3en0  SRTTWID	Imm5

Twiddle SR.T status bits, using SR.U0 .. SR.U7 as a predicate stack.

The Immed functions as a sub-command:
* 00: PUSH SR.T: Shift SR.U Left 1 bit, SR.U0=SR.T;
* 01: POP  SR.T: Shift SR.U Right 1 bit, SR.T=SR.U0;
* 02: POP  SR.T: Shift SR.U Right 2 bits, SR.T=SR.U1;
* 03: POP  SR.T: Shift SR.U Right 3 bits, SR.T=SR.U2;
* 04: AND      : SR.T = SR.T AND SR.U0;
* 05: OR       : SR.T = SR.T OR SR.U0;
* 06: AND+PUSH : AND followed by a PUSH;
* 07: OR +PUSH : OR followed by a PUSH;
* 08: CLEAR    : SR.U=0

An alternate set of ops may use U0..U3 as a THEN counter, and U4..U7 as an ELSE counter.

Alternate IF/ELSE Block:
* 0E: ELSE
* 0F: ENDIF
* 10: IF0T
* 11: IF0F
* 12: IF1T
* 13: IF1F
* 14: IFAAT
* 15: IFAAF
* 16: IFOOT
* 17: IFOOF

IF0T/IF0F will enter an IF block while also resetting the counters. This will function as a top-level IF block.

IF1T/IF1F will reuse the existing counters, entering a nested block.

IFAAT/IFAAF will combine T with the existing block via a Logical AND relation.
IFOOT/IFOOF will combine T with the existing block via a Logical OR relation.

ELSE will transition from a THEN to an ELSE block.

ENDIF will exit the block.

The True/False state of these ops will reflect whether SR.T or !SR.T will be the condition for entering the THEN block.

Following these ops, SR.T will be set to indicate which block is to be executed:
* SR.T=1: Execute the THEN block.
* SR.T=0: Execute the ELSE block.


=== SUB ===

* 11nm       SUB		Rm, Rn
* 59nm       SUB		Rm, DLR, Rn
* F0nm_1go1  SUB		Rm, Ro, Rn			//Rn=Rm-Ro, Q=0
* F0nm_1e19  SUB		Rm, Rn				//Rn=Rn-Rm

Rn=Rn-Rm
Rn=Rm-Ro
Rn=Rm-Imm

Subtract the source from the destination, storing the result in the destination register.


=== SUBx.L ===

* F0nm_5goD  SUBS.L	Rm, Ro, Rn
* F0nm_5GoD  SUBU.L	Rm, Ro, Rn

Subtract the source from the destination, storing the result in the destination register.

This variant sign or zero extends the 32 bit result to 64 bits.


=== SXENTR / SXEXIT / SVENTR ===

* 3082       SXENTR		//Enter Superuser Mode
* 3092       SUENTR		//Enter User Mode
* 30B2       SVENTR		//Enter Supervisor Mode
* F002_3080  SXENTR		//Enter Superuser Mode
* F002_3090  SUENTR		//Enter User Mode
* F002_30B0  SVENTR		//Enter Supervisor Mode

Local Mode transitions.
* The SXENTR instruction transitions to Superuser Mode.
** Valid from User Mode or Supervisor Mode.
* The SUENTR instruction transitions to User Mode (Not from SX or SV).
** Valid from Superuser Mode or Supervisor Mode.
* The SVENTR instruction transitions to Supervisor Mode.
** Valid from Superuser Mode.

These instructions are only valid within Secure-Execute Pages or from Supervisor mode.

These instructions will be specific to certain modes.


=== TRAP ===

* 36j3       TRAP	Imm4u
* 36n8       TRAP	Rn
* F068_3gn0  TRAP	Rn
* F068_3Gn0  TRAP	Xn

Generate an Interrupt.

Trap with an Imm4 uses the bits from the immediate as part of the bit-pattern for EXSR (0xC08j).


The register trap gives the full EXSR bit pattern (in the low 16 bits).
The high 48 bits of the register may give an address which will be visible to the exception handler by being copied into TEA.

In user mode, only SysCall patterns will be allowed, other patterns will result either in a fault or some other implementation-defined behavior. In supervisor mode, patterns representing a valid EXSR pattern will behave as-if this exception had occured.

Patterns which do not represent a valid EXSR pattern may result in a fault or some other implementation-defined behavior.

In a VM, an EXSR with the pattern 0xFzzz will correspond to a VM trap call. This will call a handler outside of the emulated environment. Use of a VM trap within a bare-metal implementation is undefined and should not be used.

Within a multi-core setup, bits (11:8) may be used to route the interrupt to a different core.


=== TST ===

* 14nm       TST	Rm, Rn
* F0nm_1g49  TST	Rm, Rn				//SR.T=!(Rm&Rn)
* F2n4_Cgjj  TST	Imm9u, Rn			//SR.T=!(Rm&Rn)
* F2n5_Cgjj  TST	Imm9n, Rn			//SR.T=!(Rm&Rn)

SR.T=!(Rm AND Rn)

Perform a bitwise AND of the source and destination registers, updating SR.T based on whether the result of this operation is equal to zero.

A zero result will cause SR.T to be set, and a nonzero result will cause SR.T to be cleared.

This operation will only test the low 32 bits.

For the 2R form, if E.i is Set, SR.S is updated and SR.T is unchanged.
For the 2RI form, if W.m is Set, SR.S is updated and SR.T is unchanged.
The values of the other bits are unchanged by this operation.


=== TSTQ ===

* 54nm       TSTQ	Rm, Rn
* F0nm_1G49  TSTQ	Rm, Rn				//SR.T=!(Rm&Rn), E.i=0
* F0nm_1G49  TSTQS	Rm, Rn				//SR.S=!(Rm&Rn), E.i=1
* F2n4_CGjj  TSTQ	Imm9u, Rn			//SR.T=!(Rm&Rn)
* F2n5_CGjj  TSTQ	Imm9n, Rn			//SR.T=!(Rm&Rn)

SR.T=!(Rm AND Rn)

Perform a bitwise AND of the source and destination registers, updating SR.T based on whether the result of this operation is equal to zero.

A zero result will cause SR.T to be set, and a nonzero result will cause SR.T to be cleared.

This operation will test all 64 bits.

For the 2R form, if E.i is Set, SR.S is updated and SR.T is unchanged.
For the 2RI form, if W.m is Set, SR.S is updated and SR.T is unchanged.
The values of the other bits are unchanged by this operation.


=== WEXMD (WEX) ===

* 36n9  WEXMD	Imm4 //( 0..15)
* 3En9  WEXMD	Imm4 //(16..31)

Sets the Active WEX Profile.
This instruction is No-Op if the core does not support WEX.

This instruction will enable or disable WEX based on whether or not the given profile ID is supported by the core. This will be achieved by updating the value for SR.WXE based on the profile ID given as an immediate.

If WEX is disabled, any WEX sequences encountered will be treated as if they were scalar instructions.


=== XMOV.x (XMOV, Possible) ===

* F0nm_4Go0  XMOV.B		Rn, (Xm, Disp5)		//(XMOV)
* F0nm_4go1  XMOV.X		Xn, (Xm, Disp5)		//(XMOV)
* F0nm_4Go1  XMOV.W		Rn, (Xm, Disp5)		//(XMOV)
* F0nm_4Go2  XMOV.L		Rn, (Xm, Disp5)		//(XMOV)
* F0nm_4Go3  XMOV.Q		Rn, (Xm, Disp5)		//(XMOV)
* F0nm_4Go4  XMOV.B		Rn, (Xm, Ro)		//(XMOV)
* F0nm_4go5  XMOV.X		Xn, (Xm, Ro)		//(XMOV)
* F0nm_4Go5  XMOV.W		Rn, (Xm, Ro)		//(XMOV)
* F0nm_4Go6  XMOV.L		Rn, (Xm, Ro)		//(XMOV)
* F0nm_4Go7  XMOV.Q		Rn, (Xm, Ro)		//(XMOV)
* F0nm_4Go8  XMOV.B		(Xm, Disp5), Rn		//(XMOV)
* F0nm_4go9  XMOV.X		(Xm, Disp5), Xn		//(XMOV)
* F0nm_4Go9  XMOV.W		(Xm, Disp5), Rn		//(XMOV)
* F0nm_4GoA  XMOV.L		(Xm, Disp5), Rn		//(XMOV)
* F0nm_4GoB  XMOV.Q		(Xm, Disp5), Rn		//(XMOV)
* F0nm_4GoC  XMOV.B		(Xm, Ro), Rn		//(XMOV)
* F0nm_4goD  XMOV.X		(Xm, Ro), Xn		//(XMOV)
* F0nm_4GoD  XMOV.W		(Xm, Ro), Rn		//(XMOV)
* F0nm_4GoE  XMOV.L		(Xm, Ro), Rn		//(XMOV)
* F0nm_4GoF  XMOV.Q		(Xm, Ro), Rn		//(XMOV)

These are XMOV Load/Store Ops.

If XMOV is supported, it will allow expanding the logical address space up to 96 bits with a 33-bit sign-extended displacement.

The 96-bit address will be composed from the low 48 bits of each register in the pair. The remaining upper 16 bits of each register will be used as tag bits.

Note that the XMOV instruction may enforce Bounds Checks depending on the high-order bits of the pointer.

Tagged Object Pointer
* Bits (127:112)=Ignored
* Bits (111: 64)=Address(95:48)
* Bits ( 63: 60)=Tag (0000)
* Bits ( 59: 48)=Object Tag (Ignored)
* Bits ( 47:  0)=Address(47:0)

Bounded Array (Extended)
* Bits (127:112)=ArrayBound(27:12)
* Bits (111: 64)=Address(95:48)
* Bits ( 63: 60)=Tag (0010)
* Bits ( 59: 48)=ArrayBound(11:0)
* Bits ( 47:  0)=Address(47:0)

Double Bounded Array (Extended)
* Bits (127:124)=Element Size
* Bits (123:112)=Array Lower Bound
* Bits (111: 64)=Address(95:48)
* Bits ( 63: 60)=Tag (0011)
* Bits ( 59: 48)=Array Upper Bound
* Bits ( 47:  0)=Address(47:0)

The Tag 0001 will be defined here as a non-pointer, and trying to access memory through it will raise a fault if bounds checks are supported and enabled.

Other tags here will be reserved for future extension.



=== XOR ===

* 17nm       XOR		Rm, Rn
* 5Cnm       XOR		Rm, DLR, Rn
* F0nm_1go7  XOR		Rm, Ro, Rn				//Rn=Rm XOR Ro, Q=0
* F0nm_1e79  XOR		Rm, Rn
* F2nm_7gjj  XOR		Rm, Imm9u, Rn		//

Perform a bitwise XOR of the source and destination registers, storing the result in the destination.


== GPR SIMD Extension (GSV, Optional) ==

These instructions will be considered part of the GPR SIMD Vector Extension (GSV). These instruction forms will be considered optional, and exist mostly to add rudimentary SIMD support to BJX2.

The GSVF variant will also support packed half and single precision floating-point values, whereas GSV by itself will only support packed Word and DWord operations.

Packed byte operations will not be directly supported by GSV.

Special subsets will be defined:
* GSVF: Present if both GSV and GFP exist, adds FP-SIMD
* GSVFX: Present if both GSV and GFPX exist; Supports 128-bit Vectors.


=== MOVxD (GSV) ===

* F0nm_1g8A  MOVHD		Rm, Rn			//(GSV) Move High DWord
* F0nm_1G8A  MOVLD		Rm, Rn			//(GSV) Move Low DWord
* F0nm_1gAA  MOVHLD		Rm, Rn			//(GSV) Rn=Rm (MOV High to Low)
* F0nm_1GAA  MOVLHD		Rm, Rn			//(GSV) Rn=Rm (MOV Low to High)

Partial Register Move. These MOV part of the bits from Rm into Rn, while leaving the other bits in Rn as their original value.


=== MOVxD 3R (GSV) ===

* F0nm_2go8  MOVHD		Rm, Ro, Rn		//(GSV) MOV, High DWords
* F0nm_2Go8  MOVLD		Rm, Ro, Rn		//(GSV) MOV, Low DWords
* F0nm_2go9  MOVHLD		Rm, Ro, Rn		//(GSV) MOV, High and Low DWords
* F0nm_2Go9  MOVLHD		Rm, Ro, Rn		//(GSV) MOV, Low and High DWords

The 3R forms will merge the values from two source registers into a destination register.

The high 32 bits will come from Rm, and the low 32 bits will come from Ro.

MOVHD will select the high-order bits from both registers, and MOVLD the low order bits from both registers.

MOVHLD will select the high bits from Rm, and the low bits from Ro.
MOVLHD will select the low bits from Rm, and the high bits from Ro.


=== PADD.x 3R (GSV) ===

* F0nm_2go0  PADD.W		Rm, Ro, Rn		//(GSV) Packed ADD Word
* F0nm_2Go0  PADD.L		Rm, Ro, Rn		//(GSV) Packed ADD DWord
* F0nm_2go5  PADD.F		Rm, Ro, Rn		//(GSVF) Packed FADD (2x Float)
* F0nm_2Go5  PADDX.F	Xm, Xo, Xn		//(GSVFX) Packed FADD (4x Float)
* F0nm_2goD  PADD.H 	Rm, Ro, Rn		//(GSVF) Packed FADD (4x Half)
* F0nm_2GoD  PADDX.D	Xm, Xo, Xn		//(GSVFX) Packed FADD (2x Double)
* FFw0_00ii_F0nm_2go5  PADD.X		Rm, Ro, Rn, Imm8
* FFw0_00ii_F0nm_2Go5  PADDX.X		Xm, Xo, Xn, Imm8

Packed ADD, but in 3-register form.
PADDX.x will operate on a 128-bit vector.

The Op64 encoding will add a Rounding Mode.
* The Single Precision rounding modes will be special.
** This will encode a request to go faster at the cost of precision.


=== PCMPx.x (GSV) ===

* F0nm_1gAA  PCMPEQ.H	Rm, Rn		//Packed Compare Half, Equal
* F0nm_1GAA  PCMPEQ.F	Rm, Rn		//Packed Compare Single, Equal
* F0nm_1gBA  PCMPGT.H	Rm, Rn		//Packed Compare Half, Greater
* F0nm_1GBA  PCMPGT.F	Rm, Rn		//Packed Compare Single, Greater

* F0nm_1gCA  PCMPEQ.W	Rm, Rn		//Pack Compare Word, Equal
* F0nm_1GCA  PCMPEQ.L	Rm, Rn		//Pack Compare DWord, Equal
* F0nm_1gDA  PCMPHI.W	Rm, Rn		//Pack Compare Word, Above
* F0nm_1GDA  PCMPHI.L	Rm, Rn		//Pack Compare DWord, Above
* F0nm_1gEA  PCMPGT.W	Rm, Rn		//Pack Compare Word, Greater
* F0nm_1GEA  PCMPGT.L	Rm, Rn		//Pack Compare DWord, Greater

Packed Compare.

With Word and Half will update the P/Q/R/O bits in SR depending on the result of each comparison. These will compare each element Rn with the corresponding element in Rm. The SR.P bit will correspond with the low-order element, and SR.O will correspond with the high order element.

Half of Single comparisons will be similar to Word or DWord comparisons, but will differ in that values are sign magnitude.

With Packed DWord and Float32, The T and S bits will be updated based on the comparison (T for the low element, and S for the high element).

Note that bits other than those defined for the comparison will be undefined following the operation. So, If Q=0 then S and T are undefined, and if Q=1 then P/Q/R/O are undefined. An implementation may or may not ignore Q and update both sets of bits at the same time.


=== PCSELT.x (GSV) ===

* F0nm_2go4  PCSELT.W	Rm, Ro, Rn
* F0nm_2Go4  PCSELT.L	Rm, Ro, Rn

PCSELT.L will select elements between Rm or Ro based on the value of SR.S and SR.T, storing the result in Rn. If SR.T is set, the low 32 bits from Rm is used, otherwise the low 32 bits from Ro are used. If SR.S is set, the high 32 bits from Rm is used, otherwise the high 32 bits from Ro are used.

PCSELT.W will select each Word element from Rm or Rn depending on the corresponding P/Q/R/O bits in SR. If set, the word from Rm will be selected, otherwise the value from Ro will be used.


=== PDOTT.x (GSVF, Possible) ===

* F0ni_1g9A  PDOTT.H		Imm5u, Rn	//(GSVF? Predict Dot Predicate)
* F0ni_1G9A  PDOTT.F		Imm5u, Rn	//(GSVF? Predict Dot Predicate)

Make a prediction about a Dot Vector.
These predictions will be fairly loose in terms of accuracy requirements.
In particular, the operation need not actually perform a floating point horizontal add, but may instead use lookup tables or similar to infer whether or not the predicate is likely to be true.

For inexact cases, this operation will be biased in favor of a false positive than a false negative.

The Imm5u value will encode the requested predicate (Half):
* 0: (Rx+Ry+Rz+Rw) >= 0
* 1: (Rx+Ry+Rz+Rw) <= 0
* 2: (Rx+Ry+Rz+Rw) >= 1
* 3: (Rx+Ry+Rz+Rw) <= 1

The Imm5u value will encode the requested predicate (Single):
* 0: (Rx+Ry) >= 0
* 1: (Rx+Ry) <= 0
* 2: (Rx+Ry) >= 1
* 3: (Rx+Ry) <= 1


=== PLDCH / PSTCH (GSVF) ===

* F0nm_1gCE  PLDCH		Rm, Rn		//(GSVF) Packed Half to Single (2x)
* F0nm_1GCE  PLDCHH		Rm, Rn		//(GSVF) Packed Half to Single (Hi)
* F0nm_1gDE  PLDCEHL	Rm, Rn		//(GSVF) Packed Ext-Half to Single (Lo)
* F0nm_1GDE  PLDCEHH	Rm, Rn		//(GSVF) Packed Ext-Half to Single (Hi)
* F0nm_1gEE  PSTCH		Rm, Rn		//(GSVF) Packed Single to Half (2x)

* FFw0_iiii_F88n_iiii  PLDCH	Imm32u, Rn		//(Wm=0, Wi=1) (GSVF,Op64)

Convert between Packed Half and Packed Single.

These operations will convert between Packed Half and the Packed Single format.

The Unpacking conversion will pad the low-order bits with zeroes.
The Packing conversion will truncate the low order bits.

The PLDCH instruction will unpack two Half Precision values from the low order
bits of the source register into two single-precision values in the destination.

The PLDCHH instruction will instead pull the two values from the high order bits of the source register.

The PLDCEHL and PLDCEHH will support a 3x Extended-Half format.
* The first 3 elements will be treated as Half Float numbers.
* The last element will consist of "Extension Bits" for the other elements.
* When each element is unpacked, its fraction will be extended by 5 bits.
** (52:48): Extension for First Element
** (57:53): Extension for Second Element
** (62:58): Extension for Third Element
* PLDCEHH: Will decode the Third Element.
** The Fourth element will be decoded as Zero.


=== PLDCM8x / PSTCM8x (GSVF) ===

* F0nm_1g8E  PLDCM8SH	Rm, Rn		//(GSVF) RGB32SF Unpack to RGB64F
* F0nm_1G8E  PLDCM8UH	Rm, Rn		//(GSVF) RGB32UF Unpack to RGB64F
* F0nm_1gAE  PSTCM8SH	Rm, Rn		//(GSVF) RGB32SF Pack from RGB64F
* F0nm_1GAE  PSTCM8UH	Rm, Rn		//(GSVF) RGB32UF Pack from RGB64F

** FFw0_iiii_F88n_iiii  PLDCM8SH	Imm32u, Rn	//(Wm=1, Wi=0) (GSVF,Op64)
** FFw0_iiii_F88n_iiii  PLDCM8UH	Imm32u, Rn	//(Wm=1, Wi=1) (GSVF,Op64)

These perform Packed Format Conversions for 8-bit microfloats.

These operations will convert between signed and unsigned 8-bit microfloats and the Packed Binary16 format.

The Unpacking conversion will pad the low-order bits with zeroes.
The Packing conversion will truncate the low order bits.

Formats here:
* RGB32SF: 4x FP8S (E4.F3.S), 32 bits
* RGB32UF: 4x FP8U (E4.F4), 32 bits
* RGB64F: 4x Binary16 (Packed Half), 64 bits

The FP8S and FP8U formats will consist a microfloat with a bias of 7.
* Includes Zero, does not include Inf or NaN.


=== PLDCM30AH / PSTCM30AH (RGBF) ===

* F0nm_1g9E  PLDCM30AH	Rm, Rn		//(RGBF) RGB30A Unpack to RGB64F
* F0nm_1gBE  PSTCM30AH	Rm, Rn		//(RGBF) RGB30A Pack from RGB64F

Pack or Unpack the RGB30A format.

The RGB30A Format will consist of three 10 bit fields:
* (31): Selects RGB/RGA
* (30): Selects Unsigned and Signed
* (29: 0): Depends on Selector

If Bit(31) is 0:
* (29:20): Red
* (19:10): Green
* ( 9: 0): Blue
* Values are truncated Binary16
** Unsigned, E5.F5
** Signed, E5.F4.S
* Alpha is decoded as 1.0 (3C00)

If Bit(31) is 1:
* (29:22): Alpha
* (21:15): Red
* (14: 7): Green
* ( 6: 0): Blue
** Unsigned is E4.F4 / E4.F3
** Signed is E4.F3.S / E4.F2.S

If Bit(30) is 0:
* Values are Unsigned
* Values are Signed


=== PMUL.F 3R (GSVF) ===

* F0nm_2go7  PMUL.F		Rm, Ro, Rn			//(GSVF) Packed FMUL (2x Float)
* F0nm_2Go7  PMULX.F	Xm, Xo, Xn			//(GSVFX) Packed FMUL (4x Float)
* F0nm_2goF  PMUL.H		Rm, Ro, Rn			//(GSVF) Packed FMUL (4x Half)
* F0nm_2GoF  PMULX.D	Xm, Xo, Xn			//(GSVFX) Packed FMUL (2x Double)
* FFw0_00ii_F0nm_2go7  PMUL.X		Rm, Ro, Rn, Imm8
* FFw0_00ii_F0nm_2Go7  PMULX.X		Xm, Xo, Xn, Imm8


Floating point packed multiply.
PMULX.x will operate on a 128-bit vector.

These will multiply the vectors in Rm and Ro, storing the result in Rn.
The vectors are available in 2x or 4x Single, 4x Half, or 2x Double.

The Op64 encoding will add a Rounding Mode.
* The Single Precision rounding modes will be special.
** This will encode a request to go faster at the cost of precision.


=== PMULx.W 3R (GSV) ===

* F0nm_5go1  PMULS.W	Rm, Ro, Rn			//(GSV) Packed Multiply (2x16->2x32)
* F0nm_5Go1  PMULU.W	Rm, Ro, Rn			//(GSV) Packed Multiply (2x16->2x32)
* F0nm_5go6  PMULS.LW	Rm, Ro, Rn			//(GSV) Packed Mul (Low Word)
* F0nm_5Go6  PMULU.LW	Rm, Ro, Rn			//(GSV) Packed Mul (Low Word)
* F0nm_5go7  PMULS.HW	Rm, Ro, Rn			//(GSV) Packed Mul (High Word)
* F0nm_5Go7  PMULU.HW	Rm, Ro, Rn			//(GSV) Packed Mul (High Word)

The basic 3R PMULx.W will accept vectors with two 16 bit inputs, and produce a vactor with two 32-bit products.

The LW and HW variants will consume 4-wide input vectors and produce a 4-wide output. The LW variant will keep the low order bits from the result, whereas the HW variant will keep the high-order bits.


=== PSUB.x 3R (GSV) ===

* F0nm_2go1  PSUB.W		Rm, Ro, Rn			//(GSV) Packed SUB Word
* F0nm_2Go1  PSUB.L		Rm, Ro, Rn			//(GSV) Packed SUB DWord
* F0nm_2go6  PSUB.F		Rm, Ro, Rn			//(GSVF) Packed FSUB (2x Float)
* F0nm_2Go6  PSUBX.F	Rm, Ro, Rn			//(GSVFX) Packed FSUB (4x Float)
* F0nm_2goE  PSUB.H		Rm, Ro, Rn			//(GSVF) Packed FSUB (4x Half)
* F0nm_2GoE  PSUBX.D	Xm, Xo, Xn			//(GSVFX) Packed FSUB (2x Double)

Subtract Packed Elements.

Each element from Ro is subtracted from the corresponding element of Rm.

The PSUBX variant will operate on 128-bit vectors (GPR pair).


=== PSELx.x (GSV) (Drop) ===

* F0nm_1pBA / PSELT.W	Rm, Rn		//Packed Select Word
* F0nm_1qBA / PSELF.W	Rm, Rn		//Packed Select Word
* F0nm_1PBA / PSELT.L	Rm, Rn		//Packed Select DWord
* F0nm_1QBA / PSELF.L	Rm, Rn		//Packed Select DWord

Select each Word element from Rm or Rn depending on the corresponding P/Q/R/O bits in SR, or each DWord element depending on the corresponding T or S bit.

PSELT will select the Word from Rm if the corresponding bit is Set, selecting the Rn otherwise. PSELF will instead select from Rn if the bit is set, selecting from Rm otherwise.


=== PSHUF.x ===

* F2nm_8qjj  PSHUF.B	Rm, Imm8, Rn
* F2nm_8Qjj  PSHUF.W	Rm, Imm8, Rn

Packed Shuffle of Byte or Word elements.

The elements from Rm will be reordered using the mask given in the immediate, and the results will be stored in Rn.
In the case of a Byte shuffle, the high 32 bits will be copied unchanged.

Each element will be given as a 2-bit value, with 00 mapping to the low-order bits, and 11 to the high order bits. The elements within the mask will have the same relative order (in terms of bit-positions) as the elements in the register, and will serve to select an element at each position from the source register.


=== PSHUFX.L ===

*  PSHUFX.L	Rm, Imm8, Rn

This instruction is synthetic.
Packed Shuffle of DWord element, operating on a logical 128-bit register.


=== PSCHxx.W ===

* F0nm_2goA  PSCHEQ.W	Rm, Ro, Rn
* F0nm_2GoA  PSCHEQ.B	Rm, Ro, Rn
* F0nm_2goB  PSCHNE.W	Rm, Ro, Rn
* F0nm_2GoB  PSCHNE.B	Rm, Ro, Rn

Checks if the elements in Rm match those in Ro, storing the index of the first match into Rn.

SR.T is updated based on whether or not any match was found.
SR.T will be set if the condition is true, and cleared if false.

PSCHEQ will update Rn and SR.T based on the first matching element.
PSCHNE will update Rn and SR.T based on the first non-matching element.

Elements may be either Packed Word or Packed Byte.
Elements will be numbered starting from the low-order bits.



=== RGB Pack/Unpack ===

* F0nm_1g2E  RGB5PCK32		Rm, Rn		//(RGB) RGB555A Pack from RGBA32
* F0nm_1G2E  RGB5PCK64		Rm, Rn		//(RGB) RGB555A Pack from RGBA64
* F0nm_1g3E  RGB5UPCK32		Rm, Rn		//(RGB) RGB555A Unpack to RGBA32
* F0nm_1G3E  RGB5UPCK64		Rm, Rn		//(RGB) RGB555A Unpack to RGBA64
* F0nm_1G4E  RGB32PCK64		Rm, Rn		//(RGB) RGB32 Pack from RGBA64
* F0nm_1G5E  RGB32UPCK64	Rm, Rn		//(RGB) RGB32 Unpack to RGBA64

Pack or Unpack RGB values.
Pack will convert from a wider format to a narrower one.
Unpack will convert from a narrower format to a wider one.

RGB555A:
* 0rrrrrgggggbbbbb, Opaque
* 1rrrraggggabbbba, Translucent (3 bit Alpha)

Unpacking to RGB555A to RGB32 will mirror the high bits of each component into the low bits, so 43210 is expanded to 8 bits as 43210432. Note that the alpha-blended case will unpack RGB the same as in the opaque case, so 4321a becomes 4321a432.

When unpacking Alpha, the low order bits will be filled with zeroes.
In the case of opaque pixels (MSB is zero), all alpha bits will be set to ones.

Unpacking to RGBA64 will repeat each RGBA32 component twice, for all components.

Unpacking RGB555A to RGBA64 will behave as if the value were first unpacked to RGBA32 and then from RGBA32 to RGBA64.

Packing will do the reverse process, keeping only the high order bits and discarding the rest. When packing to RGB555A, if the high 4 bits of Alpha are Set, then the pixel will be treated as opaque (and MSB will be clear), otherwise the MSB will be set and the LSB of each component will contain the one of the high 3 bits of the Alpha channel.


=== SWxP.x (GSV) ===

* F0nm_3e07  SWAP.B		Rm, Rn		//(1032) Swap E/O Bytes (Low Four Bytes)
* F0nm_3e17  SWAP.W		Rm, Rn		//(1032) Swap E/O Words (All words)
* F0nm_3e27  SWAP.8B	Rm, Rn		//       Swap E/O Bytes (All Eight Bytes)
* F0nm_3e37  SWAP.L		Rm, Rn		//(2301) Swap DWord
* F0nm_3e47  SWAP.LB	Rm, Rn		//(1023) Swap Low Two Bytes (GSV)
* F0nm_3e57  SWAP.LW	Rm, Rn		//(1023) Swap Low Two Words (GSV)
* F0nm_3e67  SWCP.LB	Rm, Rn		//(0023) Copy Low Bytes (GSV)
* F0nm_3e77  SWCP.LW	Rm, Rn		//(0023) Copy Low Words (GSV)
* F0nm_3e87  SWAP.MB	Rm, Rn		//(2103) Swap Low and Middle Byte (GSV)
* F0nm_3e97  SWAP.MW	Rm, Rn		//(2103) Swap Low and Middle Word (GSV)
* F0nm_3eA7  SWCP.MB	Rm, Rn		//(0103) Copy Low To Middle Byte (GSV)
* F0nm_3eB7  SWCP.MW	Rm, Rn		//(0103) Copy Low To Middle Word (GSV)
* F0nm_3eC7  SWAP.HB	Rm, Rn		//(3120) Swap Low and High Byte (GSV)
* F0nm_3eD7  SWAP.HW	Rm, Rn		//(3120) Swap Low and High Word (GSV)
* F0nm_3eE7  SWCP.HB	Rm, Rn		//(0120) Copy Low To High Bytes (GSV)
* F0nm_3eF7  SWCP.HW	Rm, Rn		//(0120) Copy Low To High Word (GSV)

Swap or Copy elements within a register.

SWAP.x will exchange a the low element with another element, whereas SWCP.x will copy the low element into another element.

Other than the first element, the others will be labeled as Low, Middle, and High. Low will correspond to the lower-order bits of the register, and High will correspond with the higher order bits.


=== BLERP (RGBX) ===

* F0nm_6go9            BLERP	Rm, Ro, Rn		//(RGBX) Linear Interpolate
* FFw0_00pp_F0nm_6go9  BLERPx	Rm, Ro, Rp, Rn	//(RGBX) Linear Interpolate

Linearly interpolate between two vectors.
* The vectors will be interpreted as RGBA64 or Packed UInt16.
* Rm and Ro will give the vectors to interpolate.
* Rn (3R) or Rp (4R) will give the interpolated value.
** The 3R form will use bits (15:0) as the interplator.
** The 4R will use bits (7:6) of the pp field to select an interpolator:
*** 00: Bits (15: 0) (BLERPS)
*** 01: Bits (31:16) (BLERPSH)
*** 10: Bits (47:32) (BLERPT)
*** 11: Bits (63:48) (BLERPTH)

The LERP of each component will be interpreted as:
* ValRm*(~Interp) + ValRo*Interp
* With both components treated as Unsigned.


=== BLKUAB (UAB) ===

* F0nm_6goC  BLKUAB1	Rm, Ro, Rn
* F0nm_6GoC  BLKUAB2	Rm, Ro, Rn

Extract an audio sample from a block.

These blocks will come in two formats, UAB1 and UAB2.
The UAB1 format will store 16 samples in 32 bits.
The UAB2 format will store 16 samples in 64 bits.

The block is given in Rm, with a sample index in Ro.

The result is unpacked to 16-bit linear PCM and stored in Rn.

For UAB1, the output will be encoded as:
* (15: 0): Sample Value
* (31:16): Sample Value (Repeat)

For UAB2, the output will be encoded as:
* (15: 0): Sample Value (Left)
* (31:16): Sample Value (Right)


UAB1:
* ( 5: 0): Line Start (S.E3.F2)
* (11: 6): Line End   (S.E3.F2)
* (15:12): Line Sigma (  E3.F1)
* (31:16): Sample Selector Bits

UAB2:
* ( 7: 0): Line Start (S.E3.F4)
* (15: 8): Line End   (S.E3.F4)
* (23:16): Line Sigma (Z.E3.F4)
* (31:24): Left/Right Bias (Zero for Mono)
* (63:32): Sample Selector Bits

The block will represent a line segment given as a start and end endpoint.
To decode a sample, linearly interpolate between the start and end value via the sample index.

The Sigma will represent a distance above or below this line segment, which will be either added to or subtracted from the interpolated value (based on 
the selector bits) to get the result.

The line sigma will always be positive for a UAB2 block. The use of a negative Sigma will be reserved, and may be used to escape to another block format.

The Left/Right bias will represent a constant bias which will be added to the left channel and subtracted from the right channel.


Selector bits are organized with the first sample in the low order bits, and the last sample in the high bits.

For each selector, 1 Bit:
* 0: V=Pred-Sigma
* 1: V=Pred+Sigma

For each selector, 2 Bits:
* 00: Small Negative (-0.333 * Sigma)
* 01: Large Negative (-1.000 * Sigma)
* 10: Small Positive (+0.333 * Sigma)
* 11: Large Positive (+1.000 * Sigma)

Endpoints are encoded as a microfloat value which expands into a 12-bit integer format (PCM):
0: 00000000xxxx
1: 00000001xxxx
2: 0000001xxxx0
3: 000001xxxx00
4: 00001xxxx000
5: 0001xxxx0000
6: 001xxxx00000
7: 01xxxx000000

Negative values will invert the value of the decoded sample.

Interpolation and other calculations will be performed in terms of PCM values.
An encoder should ensure that decoded values will not go out of range.


=== BLKUTX1 (RGB) ===

* F0nm_2goC  BLKUTX1	Rm, Ro, Rn

Extract pixels from blocks encoded in UTX1.

UTX1 will encode 16 pixels in 32-bits (2bpp).

The Rm field will give the pixel block, and Ro will give an index into this block. Only the low order bits of Ro will be used, with any other bits being ignored.

The output given in Rn will be in unpacked RGBA64 form, with the alpha channel set as FFFF.

For UTX1, the colors endpoints will be given as an RGB444 center, and a 4-bit Delta (YMax-YMin), with 16-bits for pixel data: PPPPDRGB.

The RGB components and delta will be expanded to 8 bits by repeating the nybble.

The Delta will be used to calculate the minimum and maximum colors, and will need to be chosen such that the RGB components do not overflow or underflow.

Where:
* Cm=Cc-(D>>1);		//Minimum
* Cn=Cm+D;			//Maximum
* Repeated for all 3 components.

Within the pixel bits, 0 will select the minimum color, and 1 will select the maximum color.


=== BLKUTX2 (RGB) ===

* F0nm_2GoC  BLKUTX2	Rm, Ro, Rn

Extract pixels from blocks encoded in UTX2.

UTX2 will encode 16 pixels in 64-bits (4bpp).

The Rm field will give the pixel block, and Ro will give an index into this block. Only the low order bits of Ro will be used, with any other bits being ignored.

The output given in Rn will be in unpacked RGBA64 form.

For UTX2, a pair of RGB555A endpoints will be given:
* (15: 0): Color A
* (31:16): Color B
* (63:32): Pixel Bits (4x4, 2bpp)

The alpha bits of the first and second endpoint will encode a mode (A,B):
* 00: Opaque Block, Linear Interpolation.
** Both endpoints will be interpreted as being Opaque.
* 01: Bit-Select Alpha
** Both endpoints will be interpreted as having Alpha.
* 10: Reserved
* 11: Translucent Block, Linear Interpolation.
** Both endpoints will be interpreted as having Alpha.

With linear interpolation, for each 2 bit pixel:
* 00: ColorB
* 01: 2/3*ColorB + 1/3*ColorA
* 10: 1/3*ColorB + 2/3*ColorA
* 11: ColorA

For interpolated translucent blocks, the alpha will be interpolated along with the color.


For bit select alpha, the high bit will be interpreted as selecting the color, with the low bit selecting the alpha. No interpolation will be performed.

With bit-selection, for each 2 bit pixel:
* 00: ColorB, AlphaB
* 01: ColorB, AlphaA
* 10: ColorA, AlphaB
* 11: ColorA, AlphaA

Pixel ordering will be such that 0 refers to the pixel at the low order bit position, and 15 at the high order bit position. These operations will not care about the internal pixel ordering within the block (which may be either raster or morton).


=== BLKUTX3 (RGBX) ===

* F0nm_6Go8  BLKUTX3H	Xm, Ro, Rn			//(RGBX) Extract Pixel, UTX3 HDR
* F0nm_6Go9  BLKUTX3L	Xm, Ro, Rn			//(RGBX) Extract Pixel, UTX3 LDR

Extract a texel from UTX3.

The UTX format will come in two sub-variants:
** LDR, with RGBA32 endpoints.
** HDR, with with FP8U endpoints in place of linear 8-bit values.

Basic Format:
* ( 31: 0): ColorA
* ( 63:32): ColorB
* ( 95:64): Selectors (RGB)
* (127:96): Selectors (Alpha)

Selectors for RGB and Alpha will be 4x4x2:
* 00: ColorB
* 01: 2/3*ColorB + 1/3*ColorA
* 10: 1/3*ColorB + 2/3*ColorA
* 11: ColorA


== GFP Instructions (GPR FPU Ops, Optional) ==

GFP will perform FPU operations with GPRs.

The BJX2 FPU aims more to be "sufficient" and "reasonably cheap" than strict adherence to IEEE 754. An FPU is allowed, but not required, to be IEEE 754 compliant.

These will reuse the existing IEEE formats, with some noted divergences:
* Rounding should be within +/- 2 ULP (rather than 0.5 ULP).
** No user-defined rounding behavior is provided for.
* The exact handling of denormals is undefined.
** Zero is to behave as Zero.
** Non-Zero denormals may behave either as zero or some tiny non-zero value.
* The results of operations involving NaN or Inf values are undefined.
** Operations on these values giving garbage results will be acceptable.
* Inf vs NaN need only check the high 4 bits of the mantissa.
** If these bits are 0, Inf may be assumed regardless of the other bits.
* Divide and Square Root are omitted.
* Handling of range overflow or underflow is required:
** If the operation exceeds the valid range, an Inf is produced.
** If the value underflows, a zero will be produced.

The nominal format of the BJX2 FPU is 64-bit Double.


There will be a second level of FPU instructions under the name GFPX:
* Adds LongDouble / Binary128
** LongDouble will nominally be defined as truncated Binary128.
** Most FPU ops are ignore the low-order bits.
** Operations which ignore the low-order bits are to zero them in results.
* Rounding is tightened to 0.51 ULP for base ops.

Another Extension, GFP_MAC, will add FMAC:
* Adds FMAC


For now, the "baseline" Binary128 support will define (Old):
* 72-bit mantissa (for the portion treated as significant).
* Though, 80-bit mantissa will be considered nominal.
* Full 15 bit exponent range.

Will define the GFPX instructions as using LongDouble (New):
* Basic representation is the same as Binary128.
** The mantissa will nominally be 80 bits.
** The actual number of mantissa bits will be implementation dependent.
* Nominally, the low bits for normal FPU operations will be ignored.
* The 32-bits of the result are to be set to zero.
* Some GFPX operations may use the full width mantissa.
** An implementation may, optionally, implement full Binary128.
** FADD, FSUB, and FMUL should use the same number of bits.


=== FABS (GFP) ===

* F0nm_1e9D  FABS		Rm, Rn		//Absolute

Get the absolute value of the double precision value in Rm and store the result in Rn. This effectively amounts to clearing bit 63 and leaving the other bits unchanged.


=== FADD (GFP) ===

* 60nm                 FADD		Rm, Rn
* F0nm_5go8            FADD		Rm, Ro, Rn
* F0nm_5Go8            FADDX	Xm, Xo, Xn		//(GFPX)
* F0nm_6goD            FADDG	Rm, Ro, Rn
* FFw0_00ii_F0nm_5go8  FADD		Rm, Ro, Rn, Imm8
* FFw0_00ii_F0nm_5Go8  FADDX	Xm, Xo, Xn, Imm8

Add the double precision value in Ro to the value from Rm and store the resulting value in Rn.

FADDX will operate instead on a LongDouble value.
This may be partial precision, with the range of mantissa bits supported being implementation defined. If supported, the minimum will be 52 bits.


In the Op64 case, the Imm8 may encode a rounding mode:
* 00: Round to Nearest
* 01: Truncate / Round towards zero.
* 02: Round toward +Inf
* 03: Round toward -Inf
* 04: Round, ULP+2, Inexact Status

* 08: Round to Nearest (Single)
* 09: Truncate Towards Zero (Single).
* 0A: Round toward +Inf (Single)
* 0B: Round toward -Inf (Single)

In rounding mode 4, the ULP will be moved upwards by 2 bits.
The low 2 bits of inputs and results will be treated as an inexact status.
If these bits hold 0, the result is exact, otherwise the result is inexact. This state will be sticky.

Behavior of the Single Modes may depend on implementation:
* May be equivalent to the basic modes (if unsupported).
* May round as-if the value were single precision.
* May serve as a hint to use a faster but less precise FPU.


=== FCMPEQ (GFP) ===

* 64nm       FCMPEQ		Rm, Rn			//(GFP) FCMPEQ
* F0nm_1gAD  FCMPEQ		Rm, Rn			//SR.T=(Rn EQ Rm)
* F0nm_1GAD  FCMPXEQ	Rm, Rn			//SR.T=(Rn EQ Rm)

Compare the double precision values in Rm and Rn for equality, setting SR.T if both values are equal, otherwise clearing SR.T.

If either value encodes a NaN, SR.T will be cleared.


=== FCMPGT (GFP) ===

* 65nm       FCMPGT		Rm, Rn			//(GFP) FCMPGT
* F0nm_1gBD  FCMPGT		Rm, Rn			//SR.T=(Rn GT Rm)
* F0nm_1GBD  FCMPXGT	Rm, Rn			//SR.T=(Rn GT Rm)

Compare if the double precision value in Rn is greated than the value in Rm, setting SR.T if this is the case, and clearing otherwise.

If either value is NaN, the resulting state of SR.T is undefined.


=== FCONV (GFPX) ===

* F2nm_8qjj  PCONV		Rm, Imm8, Rn		//E.i=1, Packed Convert
* F2nm_8Qjj  PCONVX		Rm, Imm8, Rn		//E.i=1, Packed Convert

Packed convert vectors.
The E.q parameter selects between the use of 64 and 128 bit vectors.
The vector width will be the minumum of the two vector widths.
Each vector width will be the vector size divided by the element size.
Valid encodings will be limited to a maximum of 4 elements.

Conversion between floating point and integer types will produce results scaled as integers. Conversion to integer types will be modular.

The Unit cases will be scaled to unit range (0.0 to 1.0).

Imm8:
* (3:0)=Source Element Type
* (7:4)=Destination Element Type

Types:
* 0000: Binary16
* 0001: Binary32
* 0010: Binary64
* 0011: Binary128
* 0100: Int16
* 0101: Int32
* 0110: Int64
* 0111: -
* 1000: Unit16
* 1001: Unit32
* 1010: Unit64
* 1011: -
* 1100: UInt16
* 1101: UInt32
* 1110: UInt64
* 1111: -


=== FDIVx (GFP, FDIV) ===

* F0nm_6go6 FDIV		Rm, Ro, Rn			//(FDIV) FDIV
* F0nm_6Go6 FDIVX		Rm, Ro, Rn			//(FDIV+GFPX)
* F0nm_6go7 FDIVA		Rm, Ro, Rn			//(FDIV) FDIV (Approx)
* F0nm_6Go7 FDIVXA		Rm, Ro, Rn			//(FDIV+GFPX) (Approx)

Perform a Floating-Point Divide.
Divides Rm by Ro and store the result in Rn.

The FDIVA and FDIVXA will perform a fast approximation without waiting for the result to converge on the correct answer.

This instruction will be part of the FDIV extension.


=== FLDCx (GFP) ===

* 63nm       FLDCF		Rm, Rn		//(GFP) Single->Double
* F0nm_1e0D  FLDCF		Rm, Rn		//Load Convert Float32 (Low Bits, ZX)
* F0nm_1e1D  FLDCHF		Rm, Rn		//Load Convert Float32 (High Bits)
* F0nm_1e2D  FLDCI		Rm, Rn		//Load Convert Int
* F0nm_1e3D  FLDCH		Rm, Rn		//Load Convert Half (Low16)

Load and convert the value from Rm and store the resulting double precision value in Rn.

FLDCF will pull a single precision value from the low 32 bits of Rm.
FLDCHF will pull a single precision value from the high 32 bits of Rm.

FLDCI will pull a 64-bit integer value from Rm.
FLDCH will pull a 16-bit half-float value from Rm.

When converting a narrower floating point type to a wider one:
* The low order bits will be filled with zeroes.
* The exponent will be widened with appropriate bias adjustment.
* A zero exponent will be copied as 0.
** Mantissa bits will be copied diectly.
** Essentially, denormals are ignored.
* An Inf or NaN exponent will be copied as its equivalent.
** Mantissa bits still copied directly.


=== FLDCx Imm (GFP) ===

* F88n_iiii  FLDCH		Imm16u, Rn
* F89n_iiii  FLDCH		Imm16u, Rk

* FFw0_iiii_F88n_iiii  FLDCF	Imm32u, Rn		//(Op64)
* FFw0_iiii_F89n_iiii  FLDCF	Imm32u, Rk		//(Op64)

Load a floating point immediate and convert to Double.
Conversion will be the same as that for the register instruction.


=== FMAC (GFPX) ===

* F0nm_5goB            FMAC		Rm, Ro, Rn			//(GFPX) FMAC, Rn+=Rm*Ro
* F0nm_5GoB            FMACX	Xm, Xo, Xn			//(GFPX) FMAC, LongDbl
* FFw0_00pp_F0nm_5goB  FMAC		Rm, Ro, Rp, Rn		//(GFPX) FMAC, Rn=Rm*Ro+Rp
* FFw0_00pp_F0nm_5GoB  FMACX	Xm, Xo, Rp, Xn		//(GFPX) FMAC, LongDbl

Multiply the double precision value in Ro with the value from Rm and add this to the value in Rn, storing the result in Rn.

The four register form will add against the value from Rp, storing the result in Rn.

FMACX will operate instead on a LongDouble value (partial precision).


=== FMUL (GFP) ===

* 62nm                 FMUL		Rm, Rn			//(GFP) FMUL
* F0nm_5goA            FMUL		Rm, Ro, Rn		//(GFP) FMUL
* F0nm_5GoA            FMULX	Xm, Xo, Xn		//(GFPX) FMUL
* F0nm_6goF            FMULG	Rm, Ro, Rn		//(GFP) FMUL
* FFw0_00ii_F0nm_5goA  FMUL		Rm, Ro, Rn, Imm8
* FFw0_00ii_F0nm_5GoA  FMULX	Xm, Xo, Xn, Imm8

Multiply the double precision value in Ro with the value from Rm and store the resulting value in Rn.

FMULX will operate instead on a LongDouble value.

The basic forms of FMUL will be fixed at Round-Nearest.
The FMULG form will use a dynamic rounding mode.


=== FNEG (GFP) ===

* F0nm_1g8D  FNEG		Rm, Rn		//Negate

Negate the value of the double precision value in Rm and store the result in Rn. This effectively amounts to inverting bit 63 and leaving the other bits unchanged.



=== FSQRTx (GFP, FDIV) ===

* F0nm_1gCD  FSQRT		Rm, Rn		//(FDIV) Square Root
* F0nm_1GCD  FSQRTX		Xm, Xn		//(FDIV) Square Root (GFPX)
* F0nm_1gDD  FSQRTA		Rm, Rn		//(FDIV) Square Root (Approx)
* F0nm_1GDD  FSQRTXA	Xm, Xn		//(FDIV) Square Root (GFPX, Approx)

Perform a Floating-Point Square Root.

The FSQRTA and FSQRTXA forms will perform a fast approximation without waiting for the result to converge on the correct answer.

Note that SQRT will be defined as a Signed Square Root, as-in, the output sign will be equivalent to the input sign.

This instruction will be part of the FDIV extension.


=== FSTCx (GFP) ===

* 66nm       FSTCF		Rm, Rn		//(GFP) Double->Single
* F0nm_1e4D  FSTCF		Rm, Rn		//Store Convert Float32 (Low Bits, ZX)
* F0nm_1e5D  FSTCHF		Rm, Rn		//Store Convert Float32 (High Bits)
* F0nm_1e6D  FSTCI		Rm, Rn		//Store Convert Int
* F0nm_1e7D  FSTCH		Rm, Rn		//Store Convert Half (Low16)

Convert the double precision value from Rm into the destination value and store the result in Rn.

FSTCF will produce a single precision float, which will be stored into the low 32 bits of the destination register. The high 32 bits of the register will be set to zero.

FSTCHF will produce a single precision float, which will be stored into the high 32 bits of the destination register. The low 32 bits of Rn will be kept unmodified.

FSTCI will produce a 64-bit integer output with truncation towards zero.

FSTCH will produce a half precision float, which will be stored into the low 16 bits of the destination register. The high 48 bits of the register will be set to zero.

Conversion to integer will truncate towards zero. Its output will be a 64-bit integer with undefined results if the value overflows the allowed range.


=== FSUB (GFP) ===

* 61nm                 FSUB		Rm, Rn			//(GFP) FSUB
* F0nm_5go9            FSUB		Rm, Ro, Rn		//(GFP) FSUB
* F0nm_5Go9            FSUBX	Rm, Ro, Rn		//(GFPX) FSUB
* F0nm_6goE            FSUBG	Rm, Ro, Rn		//(GFPX) FSUB
* FFw0_00ii_F0nm_5go9  FSUB		Rm, Ro, Rn, Imm8
* FFw0_00ii_F0nm_5Go9  FSUBX	Xm, Xo, Xn, Imm8

Subtract the double precision value in Ro from the value from Rm and store the resulting value in Rn.

FSUBX will operate instead on a LongDouble value.


== Jumbo Instructions ==

Moved to core ISA Spec.


=== JLDI (Jumbo Load) ===

Jumbo Load is an "instruction" which loads a 64-bit constant all at once.

Basic Encoding:
* FEjj_jjjj-F2n0_Cgjj            LDIZ		Imm32u, Rn
* FEjj_jjjj-F2n1_Cgjj            LDIN		Imm32n, Rn
* FEzz_zzzz-FEyy_yyyy-F80n_xxxx  JLDI		Imm64, Rn
* FEjj_jjjj-F2n3_Cgjj            LDIHI.L	Imm32u, Rn		//Rn=Imm32u<<16
* FEjj_jjjj-F2n3_CGjj            LDIHI.Q	Imm32u, Rn		//Rn=Imm32u<<32

The immediate fields for JLDI will be interpreted as a 64-bit value:
* zzzz_zzyy_yyyy_xxxx
* Or, essentially, the three immedite fields glued together.

JLDI will not need one or zero extension given the immediate fills an entire 64-bit register.

Jumbo LDIHI will load a 32-bit immediate with a constant shift. The Q bit will encode whether to shift the immediate left by 16 or 32 bits.

